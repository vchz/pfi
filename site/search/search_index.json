{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"PFI Documentation","text":"<p>PFI provides modular tools for score matching and flow regression on snapshot data. This documentation explains installation, basic usage, validation, and customization.</p>"},{"location":"#installation","title":"Installation","text":"<p>Clone the repository and install in editable mode:</p> <p><pre><code>git clone &lt;your-repo-url&gt;\ncd pfi\npip install -e .\n</code></pre> The package currently depends on the following other packages: <code>numpy, torch, tqdm, POT, geomloss, torchcubicspline</code>.</p>"},{"location":"#how-to-use","title":"How To Use","text":"<p>In the <code>examples/</code> folder of the repository we provide two low-dimensional examples to get your hands on the package and how to perform probability flow inference. We summarize briefly below the few key points to work with this code.</p>"},{"location":"#prepare-the-data-matrix-x","title":"Prepare the data matrix <code>X</code>","text":"<p><code>X</code> must be a 2D array of shape <code>(n_samples_total, ndim + 1)</code>. The last column is time, and the first <code>ndim</code> columns are state coordinates.</p> <pre><code>import numpy as np\nfrom pfi.utils import X_from_snapshots\n\n# snaps: list of arrays, snaps[k].shape = (n_k, ndim)\n# times: array of shape (n_snaps,)\nX = X_from_snapshots(snaps, times)\n</code></pre> <p>We propose the PFI approach as a mean to fit arbitrary Fokker-Planck Equation (FPE) to such snapshots data. In brief, us and others showed that it amounts to fitting a flow model which depends on the drift of the FPE, but also on the gradient-log probability of the data, also known as score. We illustrate here how to do this for a specific model of Fokker-Planck Equation describing constitutive transcriptional dynamics of gene expression. However, this package allows to fit any flow model, even flow models that do not depend on the score.</p>"},{"location":"#train-a-score-model","title":"Train a score model","text":"<pre><code>import torch\nimport torch.nn as nn\nfrom pfi.utils import DNN\nfrom pfi.score import ScoreMatching\n\nndim = X.shape[1] - 1\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nscore_model = DNN([ndim + 2, 64, 64, 64, ndim], activation=nn.ELU()).to(device)\n\nscore_reg = ScoreMatching(\n    model=score_model,\n    solver=\"dsm\",\n    solver_kwargs={\"L\": 10, \"n_epochs\": 2000, \"lr\": 1e-3, \"bs\": None, \"adp_flag\": 1},\n    device=device,\n)\nscore_reg.fit(X)\n</code></pre>"},{"location":"#validate-the-score","title":"Validate The Score","text":"<p><code>ScoreMatching.score(X)</code> computes per-time energy distance between generated and observed samples. Lower values indicate better match.</p> <p><pre><code>ed_per_time = score_reg.score(X)\nprint(\"Energy distance per time:\", ed_per_time)\nprint(\"Mean energy distance:\", ed_per_time.mean())\n</code></pre> You can also sample using the computed score. For the <code>solver='dsm'</code> the sampling is done with an annealed langevin dynamics scheme. A simple langevin dynamics could also do the trick.</p>"},{"location":"#choose-an-interpolant","title":"Choose an interpolant","text":"<pre><code>from pfi.flow.interpolants import ChebyshevInterpolant\n\ninterp = ChebyshevInterpolant(device=device)\n</code></pre> <p>Other available interpolants include <code>LinearInterpolant</code> and <code>SplineInterpolant</code>.</p>"},{"location":"#regress-a-flow-model","title":"Regress a flow model","text":"<pre><code>from pfi.flow import FlowRegression\nfrom pfi.flow.models import CLEFlow\n\ndrift_model = DNN([ndim, 64, 64, ndim], activation=nn.ELU()).to(device)\nflow_model = CLEFlow(\n    drift_model=drift_model,\n    score=score_reg.model_,\n    Ndim=ndim,\n    vol=1.0,\n    lx=1.0,\n)\n\nflow_reg = FlowRegression(\n    interp=interp,\n    model=flow_model,\n    growth_model=None,\n    solver=\"fm\",\n    solver_kwargs={\"n_epochs\": 2000, \"lr\": 1e-3, \"fac\": 1},\n    device=device,\n)\nflow_reg.fit(X)\n</code></pre>"},{"location":"#long-term-goal-of-this-package","title":"Long-term goal of this package","text":"<p>The package is designed for systematic model and solver comparisons. Currently, it is explicitely modular for the choice of the flow model, as long as it is an <code>nn.Module</code> which accepts input in of size<code>(batch_size, ndim+1)</code> with time as last variable. Models do not have to depend on the score, they can very well be any neural network which satisfies the aforementionned requirements.</p> <p>For the flow regression step, only the flow matching (<code>solver='fm'</code>) is available. We will work to implement other solvers (often less scalable) which we and other proposed in previous research papers. For systematic and benchmark and comparison purposes we plan to implement ode, sde and cnf based solvers for comparison purposes.</p> <p>For the score matching step, only the denoising score matching (<code>solver='dsm'</code>) is available. This is the most scalable solver we know to compute the score in high dimensions, but for benchmarking purposes we plan to implement other solvers like denoising score matching.</p> <p>We will work at updating this package by providing examples on single-cell RNA-seq data, with benchmarks and comparison.</p>"},{"location":"api/summary/","title":"Summary","text":"<ul> <li>pfi<ul> <li>flow<ul> <li>_base</li> <li>interpolants<ul> <li>_base</li> <li>_chebyshev</li> <li>_couplings</li> <li>_linear</li> <li>_spline</li> </ul> </li> <li>models</li> <li>solvers<ul> <li>_fm</li> <li>_ode</li> <li>_sde</li> </ul> </li> </ul> </li> <li>score<ul> <li>_base</li> <li>models</li> <li>solvers<ul> <li>_dsm</li> <li>_ssm</li> </ul> </li> </ul> </li> <li>utils<ul> <li>data</li> <li>nns</li> <li>simulations</li> </ul> </li> </ul> </li> </ul>"},{"location":"api/pfi/","title":"pfi","text":""},{"location":"api/pfi/#pfi","title":"<code>pfi</code>","text":"<p>Top-level package for PFI estimators and utilities.</p> <p>This module exposes the core subpackages for flow regression, score matching, and utility helpers.</p>"},{"location":"api/pfi/flow/","title":"flow","text":""},{"location":"api/pfi/flow/#pfi.flow","title":"<code>pfi.flow</code>","text":"<p>Public flow-regression APIs, models, and solver modules.</p> <p>This submodule provides flow regression estimators and the building blocks needed to train and evaluate flow models.</p>"},{"location":"api/pfi/flow/#pfi.flow.FlowRegression","title":"<code>FlowRegression(interp, model, growth_model=None, dt=1.0, solver='fm', solver_kwargs=None, device='cpu')</code>","text":"<p>Estimate drift (and optional growth) models from snapshot data.</p> <p>Parameters:</p> <ul> <li> <code>interp</code>               (<code>object</code>)           \u2013            <p>Interpolant object implementing <code>fit</code> and <code>predict</code>.</p> </li> <li> <code>model</code>               (<code>Module</code>)           \u2013            <p>Drift model consuming inputs of shape <code>(batch_size, ndim + 1)</code>.</p> </li> <li> <code>growth_model</code>               (<code>Module or None</code>, default:                   <code>None</code> )           \u2013            <p>Optional growth model used for unbalanced transport.</p> </li> <li> <code>dt</code>               (<code>float</code>, default:                   <code>1.0</code> )           \u2013            <p>Time step used by <code>predict</code> when advancing one step.</p> </li> <li> <code>solver</code>               (<code>fm</code>, default:                   <code>'fm'</code> )           \u2013            <p>Solver backend.</p> </li> <li> <code>solver_kwargs</code>               (<code>dict</code>, default:                   <code>None</code> )           \u2013            <p>Extra keyword arguments passed to the selected solver.</p> </li> <li> <code>device</code>               (<code>str or device</code>, default:                   <code>'cpu'</code> )           \u2013            <p>Device used for training and inference.</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>Ndim_</code>               (<code>int</code>)           \u2013            <p>Inferred state dimension, set during <code>fit</code>.</p> </li> <li> <code>model_</code>               (<code>Module</code>)           \u2013            <p>Fitted drift model, set during <code>fit</code>.</p> </li> <li> <code>growth_model_</code>               (<code>Module or None</code>)           \u2013            <p>Fitted growth model when provided, set during <code>fit</code>.</p> </li> <li> <code>times_</code>               (<code>ndarray of shape (n_times,)</code>)           \u2013            <p>Sorted unique training times, set during <code>fit</code>.</p> </li> </ul>"},{"location":"api/pfi/flow/#pfi.flow.FlowRegression.fit","title":"<code>fit(X, y=None)</code>","text":"<p>Fit flow models from time-augmented samples.</p> <p>Parameters:</p> <ul> <li> <code>X</code>               (<code>ndarray of shape (n_samples, ndim + 1)</code>)           \u2013            <p>Input data where the last column contains time.</p> </li> <li> <code>y</code>               (<code>None</code>, default:                   <code>None</code> )           \u2013            <p>Ignored. Present for estimator API compatibility.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>self</code> (              <code>FlowRegression</code> )          \u2013            <p>Fitted estimator.</p> </li> </ul>"},{"location":"api/pfi/flow/#pfi.flow.FlowRegression.predict","title":"<code>predict(X)</code>","text":"<p>Predict next-state positions by Euler stepping the learned drift.</p> <p>Parameters:</p> <ul> <li> <code>X</code>               (<code>array-like of shape (n_samples, ndim + 1)</code>)           \u2013            <p>Input states with time in the last column.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>x_next</code> (              <code>ndarray of shape (n_samples, ndim)</code> )          \u2013            <p>One-step predictions <code>x + dt * f(x, t)</code>.</p> </li> </ul>"},{"location":"api/pfi/flow/#pfi.flow.FlowRegression.score","title":"<code>score(X, y)</code>","text":"<p>Compute per-time energy distance between predictions and targets.</p> <p>Parameters:</p> <ul> <li> <code>X</code>               (<code>ndarray of shape (n_samples, ndim + 1)</code>)           \u2013            <p>Inputs used for prediction.</p> </li> <li> <code>y</code>               (<code>ndarray of shape (n_targets, ndim) or (n_targets, ndim + 1)</code>)           \u2013            <p>Targets. If time is present, rows at <code>t + dt</code> are selected.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>scores</code> (              <code>ndarray of shape (n_times,)</code> )          \u2013            <p>Energy distance for each unique input time.</p> </li> </ul>"},{"location":"api/pfi/flow/_base/","title":"_base","text":""},{"location":"api/pfi/flow/_base/#pfi.flow._base","title":"<code>pfi.flow._base</code>","text":"<p>Flow regression estimator wrapping flow-matching solvers.</p>"},{"location":"api/pfi/flow/_base/#pfi.flow._base.FlowRegression","title":"<code>FlowRegression(interp, model, growth_model=None, dt=1.0, solver='fm', solver_kwargs=None, device='cpu')</code>","text":"<p>Estimate drift (and optional growth) models from snapshot data.</p> <p>Parameters:</p> <ul> <li> <code>interp</code>               (<code>object</code>)           \u2013            <p>Interpolant object implementing <code>fit</code> and <code>predict</code>.</p> </li> <li> <code>model</code>               (<code>Module</code>)           \u2013            <p>Drift model consuming inputs of shape <code>(batch_size, ndim + 1)</code>.</p> </li> <li> <code>growth_model</code>               (<code>Module or None</code>, default:                   <code>None</code> )           \u2013            <p>Optional growth model used for unbalanced transport.</p> </li> <li> <code>dt</code>               (<code>float</code>, default:                   <code>1.0</code> )           \u2013            <p>Time step used by <code>predict</code> when advancing one step.</p> </li> <li> <code>solver</code>               (<code>fm</code>, default:                   <code>'fm'</code> )           \u2013            <p>Solver backend.</p> </li> <li> <code>solver_kwargs</code>               (<code>dict</code>, default:                   <code>None</code> )           \u2013            <p>Extra keyword arguments passed to the selected solver.</p> </li> <li> <code>device</code>               (<code>str or device</code>, default:                   <code>'cpu'</code> )           \u2013            <p>Device used for training and inference.</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>Ndim_</code>               (<code>int</code>)           \u2013            <p>Inferred state dimension, set during <code>fit</code>.</p> </li> <li> <code>model_</code>               (<code>Module</code>)           \u2013            <p>Fitted drift model, set during <code>fit</code>.</p> </li> <li> <code>growth_model_</code>               (<code>Module or None</code>)           \u2013            <p>Fitted growth model when provided, set during <code>fit</code>.</p> </li> <li> <code>times_</code>               (<code>ndarray of shape (n_times,)</code>)           \u2013            <p>Sorted unique training times, set during <code>fit</code>.</p> </li> </ul>"},{"location":"api/pfi/flow/_base/#pfi.flow._base.FlowRegression.fit","title":"<code>fit(X, y=None)</code>","text":"<p>Fit flow models from time-augmented samples.</p> <p>Parameters:</p> <ul> <li> <code>X</code>               (<code>ndarray of shape (n_samples, ndim + 1)</code>)           \u2013            <p>Input data where the last column contains time.</p> </li> <li> <code>y</code>               (<code>None</code>, default:                   <code>None</code> )           \u2013            <p>Ignored. Present for estimator API compatibility.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>self</code> (              <code>FlowRegression</code> )          \u2013            <p>Fitted estimator.</p> </li> </ul>"},{"location":"api/pfi/flow/_base/#pfi.flow._base.FlowRegression.predict","title":"<code>predict(X)</code>","text":"<p>Predict next-state positions by Euler stepping the learned drift.</p> <p>Parameters:</p> <ul> <li> <code>X</code>               (<code>array-like of shape (n_samples, ndim + 1)</code>)           \u2013            <p>Input states with time in the last column.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>x_next</code> (              <code>ndarray of shape (n_samples, ndim)</code> )          \u2013            <p>One-step predictions <code>x + dt * f(x, t)</code>.</p> </li> </ul>"},{"location":"api/pfi/flow/_base/#pfi.flow._base.FlowRegression.score","title":"<code>score(X, y)</code>","text":"<p>Compute per-time energy distance between predictions and targets.</p> <p>Parameters:</p> <ul> <li> <code>X</code>               (<code>ndarray of shape (n_samples, ndim + 1)</code>)           \u2013            <p>Inputs used for prediction.</p> </li> <li> <code>y</code>               (<code>ndarray of shape (n_targets, ndim) or (n_targets, ndim + 1)</code>)           \u2013            <p>Targets. If time is present, rows at <code>t + dt</code> are selected.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>scores</code> (              <code>ndarray of shape (n_times,)</code> )          \u2013            <p>Energy distance for each unique input time.</p> </li> </ul>"},{"location":"api/pfi/flow/models/","title":"models","text":""},{"location":"api/pfi/flow/models/#pfi.flow.models","title":"<code>pfi.flow.models</code>","text":"<p>Flow model classes used by flow-matching regression.</p>"},{"location":"api/pfi/flow/models/#pfi.flow.models.AutonomousFlow","title":"<code>AutonomousFlow(drift_model, Ndim)</code>","text":"<p>               Bases: <code>Module</code></p> <p>Time-independent drift model.</p> <p>Parameters:</p> <ul> <li> <code>drift_model</code>               (<code>Module</code>)           \u2013            <p>Drift network acting on state coordinates only.</p> </li> <li> <code>Ndim</code>               (<code>int</code>)           \u2013            <p>State dimension.</p> </li> </ul>"},{"location":"api/pfi/flow/models/#pfi.flow.models.CLEFlow","title":"<code>CLEFlow(drift_model, score, Ndim, vol=1.0, lx=1.0)</code>","text":"<p>               Bases: <code>Module</code></p> <p>Chemical-Langevin-inspired flow model.</p> <p>Parameters:</p> <ul> <li> <code>drift_model</code>               (<code>Module</code>)           \u2013            <p>Drift network taking <code>(batch_size, Ndim)</code> inputs.</p> </li> <li> <code>score</code>               (<code>Module</code>)           \u2013            <p>Score model taking <code>(batch_size, Ndim + 1)</code> inputs.</p> </li> <li> <code>Ndim</code>               (<code>int</code>)           \u2013            <p>State dimension.</p> </li> <li> <code>vol</code>               (<code>float</code>, default:                   <code>1.0</code> )           \u2013            <p>Volume scaling of stochastic corrections.</p> </li> <li> <code>lx</code>               (<code>float</code>, default:                   <code>1.0</code> )           \u2013            <p>Linear degradation coefficient.</p> </li> </ul>"},{"location":"api/pfi/flow/models/#pfi.flow.models.GradientFlow","title":"<code>GradientFlow(potential_model, Ndim)</code>","text":"<p>               Bases: <code>Module</code></p> <p>Gradient flow model parameterized by a scalar potential.</p> <p>Parameters:</p> <ul> <li> <code>potential_model</code>               (<code>Module</code>)           \u2013            <p>Network mapping <code>(batch_size, Ndim)</code> to scalar potential values.</p> </li> <li> <code>Ndim</code>               (<code>int</code>)           \u2013            <p>State dimension.</p> </li> </ul>"},{"location":"api/pfi/flow/models/#pfi.flow.models.OUFlow","title":"<code>OUFlow(B, score, D)</code>","text":"<p>               Bases: <code>Module</code></p> <p>Ornstein-Uhlenbeck flow model using an external score function.</p> <p>Parameters:</p> <ul> <li> <code>B</code>               (<code>torch.Tensor of shape (ndim, ndim)</code>)           \u2013            <p>Drift matrix.</p> </li> <li> <code>score</code>               (<code>Module</code>)           \u2013            <p>Score model mapping <code>(batch_size, ndim + 1)</code> to <code>(batch_size, ndim)</code>.</p> </li> <li> <code>D</code>               (<code>torch.Tensor of shape (ndim, ndim)</code>)           \u2013            <p>Diffusion matrix.</p> </li> </ul>"},{"location":"api/pfi/flow/interpolants/","title":"interpolants","text":""},{"location":"api/pfi/flow/interpolants/#pfi.flow.interpolants","title":"<code>pfi.flow.interpolants</code>","text":""},{"location":"api/pfi/flow/interpolants/#pfi.flow.interpolants.BaseInterpolant","title":"<code>BaseInterpolant(device='cpu')</code>","text":"<p>Abstract base class for trajectory interpolants.</p> <p>Parameters:</p> <ul> <li> <code>device</code>               (<code>str or device</code>, default:                   <code>'cpu'</code> )           \u2013            <p>Device used by derived interpolants.</p> </li> </ul>"},{"location":"api/pfi/flow/interpolants/#pfi.flow.interpolants.BaseInterpolant.fit","title":"<code>fit(nodes_fit, Dist)</code>","text":"<p>Store fit data and call implementation-specific fitting.</p> <p>Parameters:</p> <ul> <li> <code>nodes_fit</code>               (<code>torch.Tensor of shape (batch_size, n_nodes)</code>)           \u2013            <p>Time nodes used for fitting.</p> </li> <li> <code>Dist</code>               (<code>torch.Tensor of shape (batch_size, n_nodes, ndim)</code>)           \u2013            <p>Trajectory values at <code>nodes_fit</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>self</code> (              <code>BaseInterpolant</code> )          \u2013            <p>Fitted interpolant.</p> </li> </ul>"},{"location":"api/pfi/flow/interpolants/#pfi.flow.interpolants.BaseInterpolant.predict","title":"<code>predict(t_eval)</code>","text":"<p>Evaluate interpolant and derivative at requested nodes.</p> <p>Parameters:</p> <ul> <li> <code>t_eval</code>               (<code>torch.Tensor of shape (batch_size, n_eval)</code>)           \u2013            <p>Evaluation nodes.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>x_interp</code> (              <code>torch.Tensor of shape (batch_size, n_eval, ndim)</code> )          \u2013            <p>Interpolated trajectories.</p> </li> <li> <code>dx_interp</code> (              <code>torch.Tensor of shape (batch_size, n_eval, ndim)</code> )          \u2013            <p>Time derivatives at evaluation nodes.</p> </li> </ul>"},{"location":"api/pfi/flow/interpolants/#pfi.flow.interpolants.ChebyshevInterpolant","title":"<code>ChebyshevInterpolant(reg_=0.01, device='cpu')</code>","text":"<p>               Bases: <code>BaseInterpolant</code></p> <p>Regularized Chebyshev interpolant for batched trajectories.</p> <p>Parameters:</p> <ul> <li> <code>reg_</code>               (<code>float</code>, default:                   <code>0.01</code> )           \u2013            <p>Curvature regularization weight.</p> </li> <li> <code>device</code>               (<code>str or device</code>, default:                   <code>'cpu'</code> )           \u2013            <p>Computation device.</p> </li> </ul>"},{"location":"api/pfi/flow/interpolants/#pfi.flow.interpolants.ChebyshevInterpolant.fit","title":"<code>fit(nodes_fit, Dist)</code>","text":"<p>Store fit data and call implementation-specific fitting.</p> <p>Parameters:</p> <ul> <li> <code>nodes_fit</code>               (<code>torch.Tensor of shape (batch_size, n_nodes)</code>)           \u2013            <p>Time nodes used for fitting.</p> </li> <li> <code>Dist</code>               (<code>torch.Tensor of shape (batch_size, n_nodes, ndim)</code>)           \u2013            <p>Trajectory values at <code>nodes_fit</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>self</code> (              <code>BaseInterpolant</code> )          \u2013            <p>Fitted interpolant.</p> </li> </ul>"},{"location":"api/pfi/flow/interpolants/#pfi.flow.interpolants.ChebyshevInterpolant.predict","title":"<code>predict(t_eval)</code>","text":"<p>Evaluate interpolated trajectories and derivatives.</p> <p>Parameters:</p> <ul> <li> <code>t_eval</code>               (<code>torch.Tensor of shape (batch_size, n_eval)</code>)           \u2013            <p>Evaluation nodes.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>x_interp</code> (              <code>torch.Tensor of shape (batch_size, n_eval, ndim)</code> )          \u2013            <p>Interpolated trajectories.</p> </li> <li> <code>dx_interp</code> (              <code>torch.Tensor of shape (batch_size, n_eval, ndim)</code> )          \u2013            <p>Time derivatives.</p> </li> </ul>"},{"location":"api/pfi/flow/interpolants/#pfi.flow.interpolants.LinearInterpolant","title":"<code>LinearInterpolant(device='cpu')</code>","text":"<p>               Bases: <code>BaseInterpolant</code></p> <p>Batched piecewise-linear interpolant.</p> <p>Parameters:</p> <ul> <li> <code>device</code>               (<code>str or device</code>, default:                   <code>'cpu'</code> )           \u2013            <p>Computation device inherited from <code>pfi.flow.interpolants.BaseInterpolant</code>.</p> </li> </ul>"},{"location":"api/pfi/flow/interpolants/#pfi.flow.interpolants.LinearInterpolant.fit","title":"<code>fit(nodes_fit, Dist)</code>","text":"<p>Store fit data and call implementation-specific fitting.</p> <p>Parameters:</p> <ul> <li> <code>nodes_fit</code>               (<code>torch.Tensor of shape (batch_size, n_nodes)</code>)           \u2013            <p>Time nodes used for fitting.</p> </li> <li> <code>Dist</code>               (<code>torch.Tensor of shape (batch_size, n_nodes, ndim)</code>)           \u2013            <p>Trajectory values at <code>nodes_fit</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>self</code> (              <code>BaseInterpolant</code> )          \u2013            <p>Fitted interpolant.</p> </li> </ul>"},{"location":"api/pfi/flow/interpolants/#pfi.flow.interpolants.LinearInterpolant.predict","title":"<code>predict(t_eval)</code>","text":"<p>Evaluate linear interpolation and piecewise-constant derivative.</p> <p>Parameters:</p> <ul> <li> <code>t_eval</code>               (<code>torch.Tensor of shape (batch_size, n_eval)</code>)           \u2013            <p>Evaluation nodes.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>interp</code> (              <code>torch.Tensor of shape (batch_size, n_eval, ndim)</code> )          \u2013            <p>Interpolated trajectories.</p> </li> <li> <code>deriv</code> (              <code>torch.Tensor of shape (batch_size, n_eval, ndim)</code> )          \u2013            <p>Piecewise-constant derivatives.</p> </li> </ul>"},{"location":"api/pfi/flow/interpolants/#pfi.flow.interpolants.SplineInterpolant","title":"<code>SplineInterpolant(device='cpu')</code>","text":"<p>               Bases: <code>BaseInterpolant</code></p> <p>Batched natural cubic spline interpolant.</p> <p>Parameters:</p> <ul> <li> <code>device</code>               (<code>str or device</code>, default:                   <code>'cpu'</code> )           \u2013            <p>Computation device inherited from <code>pfi.flow.interpolants.BaseInterpolant</code>.</p> </li> </ul>"},{"location":"api/pfi/flow/interpolants/#pfi.flow.interpolants.SplineInterpolant.fit","title":"<code>fit(nodes_fit, Dist)</code>","text":"<p>Store fit data and call implementation-specific fitting.</p> <p>Parameters:</p> <ul> <li> <code>nodes_fit</code>               (<code>torch.Tensor of shape (batch_size, n_nodes)</code>)           \u2013            <p>Time nodes used for fitting.</p> </li> <li> <code>Dist</code>               (<code>torch.Tensor of shape (batch_size, n_nodes, ndim)</code>)           \u2013            <p>Trajectory values at <code>nodes_fit</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>self</code> (              <code>BaseInterpolant</code> )          \u2013            <p>Fitted interpolant.</p> </li> </ul>"},{"location":"api/pfi/flow/interpolants/#pfi.flow.interpolants.SplineInterpolant.predict","title":"<code>predict(t_eval)</code>","text":"<p>Evaluate spline interpolation and derivative.</p> <p>Parameters:</p> <ul> <li> <code>t_eval</code>               (<code>torch.Tensor of shape (batch_size, n_eval) or (n_eval,)</code>)           \u2013            <p>Evaluation nodes.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>eval_</code> (              <code>torch.Tensor of shape (batch_size, n_eval, ndim)</code> )          \u2013            <p>Interpolated trajectories.</p> </li> <li> <code>derv_</code> (              <code>torch.Tensor of shape (batch_size, n_eval, ndim)</code> )          \u2013            <p>Derivative trajectories.</p> </li> </ul>"},{"location":"api/pfi/flow/interpolants/#pfi.flow.interpolants.MMOT_trajectories","title":"<code>MMOT_trajectories(dist, device='cpu')</code>","text":"<p>Construct multi-marginal OT trajectories from snapshot lists.</p> <p>Parameters:</p> <ul> <li> <code>dist</code>               (<code>list of array-like, length nsnaps</code>)           \u2013            <p><code>dist[k]</code> has shape <code>(n_k, ndim)</code>.</p> </li> <li> <code>device</code>               (<code>str or device</code>, default:                   <code>'cpu'</code> )           \u2013            <p>Target device for returned trajectories.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>dist</code> (              <code>torch.Tensor of shape (nsnaps, nsamples, ndim)</code> )          \u2013            <p>Subsampled and stacked snapshots.</p> </li> <li> <code>batch_ot_samples</code> (              <code>torch.Tensor of shape (nsnaps, nsamples, ndim)</code> )          \u2013            <p>OT-coupled trajectories across snapshots.</p> </li> </ul>"},{"location":"api/pfi/flow/interpolants/#pfi.flow.interpolants.select_best_lambda","title":"<code>select_best_lambda(batch_ot_samples, data_batch, eval_batch, device, lam_vals=None, rel_tol=0.8, verbose=True)</code>","text":"<p>Select regularization strength from velocity-magnitude reduction.</p> <p>Parameters:</p> <ul> <li> <code>batch_ot_samples</code>               (<code>torch.Tensor of shape (batch_size, n_nodes, ndim)</code>)           \u2013            <p>Training trajectories.</p> </li> <li> <code>data_batch</code>               (<code>torch.Tensor of shape (batch_size, n_nodes)</code>)           \u2013            <p>Fit nodes.</p> </li> <li> <code>eval_batch</code>               (<code>torch.Tensor of shape (batch_size, n_eval)</code>)           \u2013            <p>Evaluation nodes.</p> </li> <li> <code>device</code>               (<code>str or device</code>)           \u2013            <p>Computation device.</p> </li> <li> <code>lam_vals</code>               (<code>array-like of shape (n_lambdas,)</code>, default:                   <code>None</code> )           \u2013            <p>Candidate regularization values.</p> </li> <li> <code>rel_tol</code>               (<code>float</code>, default:                   <code>0.8</code> )           \u2013            <p>Minimum relative reduction threshold.</p> </li> <li> <code>verbose</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If <code>True</code>, print diagnostics.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>best_lambda</code> (              <code>float</code> )          \u2013            <p>Selected regularization value.</p> </li> <li> <code>lam_arr</code> (              <code>ndarray of shape (n_lambdas,)</code> )          \u2013            <p>Candidate values evaluated.</p> </li> <li> <code>vel_mag</code> (              <code>ndarray of shape (n_lambdas,)</code> )          \u2013            <p>Mean squared derivative magnitudes for each candidate.</p> </li> </ul>"},{"location":"api/pfi/flow/interpolants/_base/","title":"_base","text":""},{"location":"api/pfi/flow/interpolants/_base/#pfi.flow.interpolants._base","title":"<code>pfi.flow.interpolants._base</code>","text":"<p>Base interpolant interface used by flow-matching solvers.</p>"},{"location":"api/pfi/flow/interpolants/_base/#pfi.flow.interpolants._base.BaseInterpolant","title":"<code>BaseInterpolant(device='cpu')</code>","text":"<p>Abstract base class for trajectory interpolants.</p> <p>Parameters:</p> <ul> <li> <code>device</code>               (<code>str or device</code>, default:                   <code>'cpu'</code> )           \u2013            <p>Device used by derived interpolants.</p> </li> </ul>"},{"location":"api/pfi/flow/interpolants/_base/#pfi.flow.interpolants._base.BaseInterpolant.fit","title":"<code>fit(nodes_fit, Dist)</code>","text":"<p>Store fit data and call implementation-specific fitting.</p> <p>Parameters:</p> <ul> <li> <code>nodes_fit</code>               (<code>torch.Tensor of shape (batch_size, n_nodes)</code>)           \u2013            <p>Time nodes used for fitting.</p> </li> <li> <code>Dist</code>               (<code>torch.Tensor of shape (batch_size, n_nodes, ndim)</code>)           \u2013            <p>Trajectory values at <code>nodes_fit</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>self</code> (              <code>BaseInterpolant</code> )          \u2013            <p>Fitted interpolant.</p> </li> </ul>"},{"location":"api/pfi/flow/interpolants/_base/#pfi.flow.interpolants._base.BaseInterpolant.predict","title":"<code>predict(t_eval)</code>","text":"<p>Evaluate interpolant and derivative at requested nodes.</p> <p>Parameters:</p> <ul> <li> <code>t_eval</code>               (<code>torch.Tensor of shape (batch_size, n_eval)</code>)           \u2013            <p>Evaluation nodes.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>x_interp</code> (              <code>torch.Tensor of shape (batch_size, n_eval, ndim)</code> )          \u2013            <p>Interpolated trajectories.</p> </li> <li> <code>dx_interp</code> (              <code>torch.Tensor of shape (batch_size, n_eval, ndim)</code> )          \u2013            <p>Time derivatives at evaluation nodes.</p> </li> </ul>"},{"location":"api/pfi/flow/interpolants/_chebyshev/","title":"_chebyshev","text":""},{"location":"api/pfi/flow/interpolants/_chebyshev/#pfi.flow.interpolants._chebyshev","title":"<code>pfi.flow.interpolants._chebyshev</code>","text":"<p>Chebyshev polynomial interpolants and regularization selection.</p>"},{"location":"api/pfi/flow/interpolants/_chebyshev/#pfi.flow.interpolants._chebyshev.ChebyshevInterpolant","title":"<code>ChebyshevInterpolant(reg_=0.01, device='cpu')</code>","text":"<p>               Bases: <code>BaseInterpolant</code></p> <p>Regularized Chebyshev interpolant for batched trajectories.</p> <p>Parameters:</p> <ul> <li> <code>reg_</code>               (<code>float</code>, default:                   <code>0.01</code> )           \u2013            <p>Curvature regularization weight.</p> </li> <li> <code>device</code>               (<code>str or device</code>, default:                   <code>'cpu'</code> )           \u2013            <p>Computation device.</p> </li> </ul>"},{"location":"api/pfi/flow/interpolants/_chebyshev/#pfi.flow.interpolants._chebyshev.ChebyshevInterpolant.fit","title":"<code>fit(nodes_fit, Dist)</code>","text":"<p>Store fit data and call implementation-specific fitting.</p> <p>Parameters:</p> <ul> <li> <code>nodes_fit</code>               (<code>torch.Tensor of shape (batch_size, n_nodes)</code>)           \u2013            <p>Time nodes used for fitting.</p> </li> <li> <code>Dist</code>               (<code>torch.Tensor of shape (batch_size, n_nodes, ndim)</code>)           \u2013            <p>Trajectory values at <code>nodes_fit</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>self</code> (              <code>BaseInterpolant</code> )          \u2013            <p>Fitted interpolant.</p> </li> </ul>"},{"location":"api/pfi/flow/interpolants/_chebyshev/#pfi.flow.interpolants._chebyshev.ChebyshevInterpolant.predict","title":"<code>predict(t_eval)</code>","text":"<p>Evaluate interpolated trajectories and derivatives.</p> <p>Parameters:</p> <ul> <li> <code>t_eval</code>               (<code>torch.Tensor of shape (batch_size, n_eval)</code>)           \u2013            <p>Evaluation nodes.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>x_interp</code> (              <code>torch.Tensor of shape (batch_size, n_eval, ndim)</code> )          \u2013            <p>Interpolated trajectories.</p> </li> <li> <code>dx_interp</code> (              <code>torch.Tensor of shape (batch_size, n_eval, ndim)</code> )          \u2013            <p>Time derivatives.</p> </li> </ul>"},{"location":"api/pfi/flow/interpolants/_chebyshev/#pfi.flow.interpolants._chebyshev.batched_chebyshev_interpolate","title":"<code>batched_chebyshev_interpolate(t_points, x_points, degree=None, lambda_reg=0.0, penalty='none')</code>","text":"<p>Fit batched Chebyshev polynomials and return evaluation callables.</p> <p>Parameters:</p> <ul> <li> <code>t_points</code>               (<code>torch.Tensor of shape (batch_size, n_points)</code>)           \u2013            <p>Time nodes for fitting.</p> </li> <li> <code>x_points</code>               (<code>torch.Tensor of shape (batch_size, n_points, ndim)</code>)           \u2013            <p>Trajectory values at <code>t_points</code>.</p> </li> <li> <code>degree</code>               (<code>int or None</code>, default:                   <code>None</code> )           \u2013            <p>Polynomial degree. If <code>None</code>, uses <code>n_points - 1</code>.</p> </li> <li> <code>lambda_reg</code>               (<code>float</code>, default:                   <code>0.0</code> )           \u2013            <p>Regularization weight.</p> </li> <li> <code>penalty</code>               (<code>(none, l2, velocity, curvature)</code>, default:                   <code>'none'</code> )           \u2013            <p>Regularization profile on coefficients.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>coeffs</code> (              <code>torch.Tensor of shape (batch_size, degree + 1, ndim)</code> )          \u2013            <p>Fitted Chebyshev coefficients.</p> </li> <li> <code>interpolant</code> (              <code>callable</code> )          \u2013            <p>Function mapping <code>t_eval</code> of shape <code>(batch_size, n_eval)</code> to interpolated values of shape <code>(batch_size, n_eval, ndim)</code>.</p> </li> <li> <code>derivative</code> (              <code>callable</code> )          \u2013            <p>Function mapping <code>t_eval</code> of shape <code>(batch_size, n_eval)</code> to derivatives of shape <code>(batch_size, n_eval, ndim)</code>.</p> </li> <li> <code>bounds</code> (              <code>tuple of torch.Tensor</code> )          \u2013            <p>Tuple <code>(a, bmax)</code> each of shape <code>(batch_size, 1)</code> used for scaling.</p> </li> </ul>"},{"location":"api/pfi/flow/interpolants/_chebyshev/#pfi.flow.interpolants._chebyshev.chebyshev_U_basis_matrix","title":"<code>chebyshev_U_basis_matrix(s, degree)</code>","text":"<p>Compute second-kind Chebyshev basis values.</p> <p>Parameters:</p> <ul> <li> <code>s</code>               (<code>torch.Tensor of shape (batch_size, n_points)</code>)           \u2013            <p>Scaled nodes in <code>[-1, 1]</code>.</p> </li> <li> <code>degree</code>               (<code>int</code>)           \u2013            <p>Maximum polynomial degree.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>basis</code> (              <code>torch.Tensor of shape (batch_size, n_points, degree)</code> )          \u2013            <p>Basis matrix <code>[U_0(s), ..., U_{degree-1}(s)]</code>.</p> </li> </ul>"},{"location":"api/pfi/flow/interpolants/_chebyshev/#pfi.flow.interpolants._chebyshev.chebyshev_basis_matrix","title":"<code>chebyshev_basis_matrix(s, degree)</code>","text":"<p>Compute first-kind Chebyshev basis values.</p> <p>Parameters:</p> <ul> <li> <code>s</code>               (<code>torch.Tensor of shape (batch_size, n_points)</code>)           \u2013            <p>Scaled nodes in <code>[-1, 1]</code>.</p> </li> <li> <code>degree</code>               (<code>int</code>)           \u2013            <p>Maximum polynomial degree.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>basis</code> (              <code>torch.Tensor of shape (batch_size, n_points, degree + 1)</code> )          \u2013            <p>Basis matrix <code>[T_0(s), ..., T_degree(s)]</code>.</p> </li> </ul>"},{"location":"api/pfi/flow/interpolants/_chebyshev/#pfi.flow.interpolants._chebyshev.select_best_lambda","title":"<code>select_best_lambda(batch_ot_samples, data_batch, eval_batch, device, lam_vals=None, rel_tol=0.8, verbose=True)</code>","text":"<p>Select regularization strength from velocity-magnitude reduction.</p> <p>Parameters:</p> <ul> <li> <code>batch_ot_samples</code>               (<code>torch.Tensor of shape (batch_size, n_nodes, ndim)</code>)           \u2013            <p>Training trajectories.</p> </li> <li> <code>data_batch</code>               (<code>torch.Tensor of shape (batch_size, n_nodes)</code>)           \u2013            <p>Fit nodes.</p> </li> <li> <code>eval_batch</code>               (<code>torch.Tensor of shape (batch_size, n_eval)</code>)           \u2013            <p>Evaluation nodes.</p> </li> <li> <code>device</code>               (<code>str or device</code>)           \u2013            <p>Computation device.</p> </li> <li> <code>lam_vals</code>               (<code>array-like of shape (n_lambdas,)</code>, default:                   <code>None</code> )           \u2013            <p>Candidate regularization values.</p> </li> <li> <code>rel_tol</code>               (<code>float</code>, default:                   <code>0.8</code> )           \u2013            <p>Minimum relative reduction threshold.</p> </li> <li> <code>verbose</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If <code>True</code>, print diagnostics.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>best_lambda</code> (              <code>float</code> )          \u2013            <p>Selected regularization value.</p> </li> <li> <code>lam_arr</code> (              <code>ndarray of shape (n_lambdas,)</code> )          \u2013            <p>Candidate values evaluated.</p> </li> <li> <code>vel_mag</code> (              <code>ndarray of shape (n_lambdas,)</code> )          \u2013            <p>Mean squared derivative magnitudes for each candidate.</p> </li> </ul>"},{"location":"api/pfi/flow/interpolants/_couplings/","title":"_couplings","text":""},{"location":"api/pfi/flow/interpolants/_couplings/#pfi.flow.interpolants._couplings","title":"<code>pfi.flow.interpolants._couplings</code>","text":"<p>Optimal-transport coupling and trajectory sampling utilities.</p>"},{"location":"api/pfi/flow/interpolants/_couplings/#pfi.flow.interpolants._couplings.MMOT_trajectories","title":"<code>MMOT_trajectories(dist, device='cpu')</code>","text":"<p>Construct multi-marginal OT trajectories from snapshot lists.</p> <p>Parameters:</p> <ul> <li> <code>dist</code>               (<code>list of array-like, length nsnaps</code>)           \u2013            <p><code>dist[k]</code> has shape <code>(n_k, ndim)</code>.</p> </li> <li> <code>device</code>               (<code>str or device</code>, default:                   <code>'cpu'</code> )           \u2013            <p>Target device for returned trajectories.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>dist</code> (              <code>torch.Tensor of shape (nsnaps, nsamples, ndim)</code> )          \u2013            <p>Subsampled and stacked snapshots.</p> </li> <li> <code>batch_ot_samples</code> (              <code>torch.Tensor of shape (nsnaps, nsamples, ndim)</code> )          \u2013            <p>OT-coupled trajectories across snapshots.</p> </li> </ul>"},{"location":"api/pfi/flow/interpolants/_couplings/#pfi.flow.interpolants._couplings.compute_pairwise_ot_plans","title":"<code>compute_pairwise_ot_plans(samples, method='exact', epsilon=0.01)</code>","text":"<p>Compute pairwise transport plans between consecutive snapshots.</p> <p>Parameters:</p> <ul> <li> <code>samples</code>               (<code>torch.Tensor of shape (k_plus_1, b, ndim)</code>)           \u2013            <p>Snapshot samples with equal sample count <code>b</code>.</p> </li> <li> <code>method</code>               (<code>(exact, sinkhorn)</code>, default:                   <code>'exact'</code> )           \u2013            <p>OT solver used for each consecutive pair.</p> </li> <li> <code>epsilon</code>               (<code>float</code>, default:                   <code>1e-2</code> )           \u2013            <p>Entropic regularization when <code>method='sinkhorn'</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>pi_list</code> (              <code>list of length k_plus_1 - 1</code> )          \u2013            <p>Each entry is an ndarray of shape <code>(b, b)</code> containing an OT plan.</p> </li> </ul>"},{"location":"api/pfi/flow/interpolants/_couplings/#pfi.flow.interpolants._couplings.get_sample_paths","title":"<code>get_sample_paths(samples, trajectories, num_paths)</code>","text":"<p>Gather full sample paths from trajectory indices.</p> <p>Parameters:</p> <ul> <li> <code>samples</code>               (<code>torch.Tensor of shape (k_plus_1, b, ndim)</code>)           \u2013            <p>Snapshot samples.</p> </li> <li> <code>trajectories</code>               (<code>ndarray of shape (num_paths, k_plus_1)</code>)           \u2013            <p>Index trajectories.</p> </li> <li> <code>num_paths</code>               (<code>int</code>)           \u2013            <p>Number of paths to extract.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>sample_paths</code> (              <code>torch.Tensor of shape (k_plus_1, num_paths, ndim)</code> )          \u2013            <p>Reconstructed paths.</p> </li> </ul>"},{"location":"api/pfi/flow/interpolants/_couplings/#pfi.flow.interpolants._couplings.sample_trajectory","title":"<code>sample_trajectory(pi_list, num_samples=1)</code>","text":"<p>Sample discrete index trajectories from chained OT plans.</p> <p>Parameters:</p> <ul> <li> <code>pi_list</code>               (<code>list of length k</code>)           \u2013            <p>Pairwise OT plans. Each plan has shape <code>(b, b)</code>.</p> </li> <li> <code>num_samples</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>Number of trajectories to sample.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>trajectories</code> (              <code>ndarray of shape (num_samples, k + 1)</code> )          \u2013            <p>Sampled index trajectories through snapshots.</p> </li> </ul>"},{"location":"api/pfi/flow/interpolants/_linear/","title":"_linear","text":""},{"location":"api/pfi/flow/interpolants/_linear/#pfi.flow.interpolants._linear","title":"<code>pfi.flow.interpolants._linear</code>","text":"<p>Piecewise-linear interpolant for trajectory data.</p>"},{"location":"api/pfi/flow/interpolants/_linear/#pfi.flow.interpolants._linear.LinearInterpolant","title":"<code>LinearInterpolant(device='cpu')</code>","text":"<p>               Bases: <code>BaseInterpolant</code></p> <p>Batched piecewise-linear interpolant.</p> <p>Parameters:</p> <ul> <li> <code>device</code>               (<code>str or device</code>, default:                   <code>'cpu'</code> )           \u2013            <p>Computation device inherited from <code>pfi.flow.interpolants.BaseInterpolant</code>.</p> </li> </ul>"},{"location":"api/pfi/flow/interpolants/_linear/#pfi.flow.interpolants._linear.LinearInterpolant.fit","title":"<code>fit(nodes_fit, Dist)</code>","text":"<p>Store fit data and call implementation-specific fitting.</p> <p>Parameters:</p> <ul> <li> <code>nodes_fit</code>               (<code>torch.Tensor of shape (batch_size, n_nodes)</code>)           \u2013            <p>Time nodes used for fitting.</p> </li> <li> <code>Dist</code>               (<code>torch.Tensor of shape (batch_size, n_nodes, ndim)</code>)           \u2013            <p>Trajectory values at <code>nodes_fit</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>self</code> (              <code>BaseInterpolant</code> )          \u2013            <p>Fitted interpolant.</p> </li> </ul>"},{"location":"api/pfi/flow/interpolants/_linear/#pfi.flow.interpolants._linear.LinearInterpolant.predict","title":"<code>predict(t_eval)</code>","text":"<p>Evaluate linear interpolation and piecewise-constant derivative.</p> <p>Parameters:</p> <ul> <li> <code>t_eval</code>               (<code>torch.Tensor of shape (batch_size, n_eval)</code>)           \u2013            <p>Evaluation nodes.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>interp</code> (              <code>torch.Tensor of shape (batch_size, n_eval, ndim)</code> )          \u2013            <p>Interpolated trajectories.</p> </li> <li> <code>deriv</code> (              <code>torch.Tensor of shape (batch_size, n_eval, ndim)</code> )          \u2013            <p>Piecewise-constant derivatives.</p> </li> </ul>"},{"location":"api/pfi/flow/interpolants/_spline/","title":"_spline","text":""},{"location":"api/pfi/flow/interpolants/_spline/#pfi.flow.interpolants._spline","title":"<code>pfi.flow.interpolants._spline</code>","text":"<p>Natural cubic spline interpolant for trajectory data.</p>"},{"location":"api/pfi/flow/interpolants/_spline/#pfi.flow.interpolants._spline.SplineInterpolant","title":"<code>SplineInterpolant(device='cpu')</code>","text":"<p>               Bases: <code>BaseInterpolant</code></p> <p>Batched natural cubic spline interpolant.</p> <p>Parameters:</p> <ul> <li> <code>device</code>               (<code>str or device</code>, default:                   <code>'cpu'</code> )           \u2013            <p>Computation device inherited from <code>pfi.flow.interpolants.BaseInterpolant</code>.</p> </li> </ul>"},{"location":"api/pfi/flow/interpolants/_spline/#pfi.flow.interpolants._spline.SplineInterpolant.fit","title":"<code>fit(nodes_fit, Dist)</code>","text":"<p>Store fit data and call implementation-specific fitting.</p> <p>Parameters:</p> <ul> <li> <code>nodes_fit</code>               (<code>torch.Tensor of shape (batch_size, n_nodes)</code>)           \u2013            <p>Time nodes used for fitting.</p> </li> <li> <code>Dist</code>               (<code>torch.Tensor of shape (batch_size, n_nodes, ndim)</code>)           \u2013            <p>Trajectory values at <code>nodes_fit</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>self</code> (              <code>BaseInterpolant</code> )          \u2013            <p>Fitted interpolant.</p> </li> </ul>"},{"location":"api/pfi/flow/interpolants/_spline/#pfi.flow.interpolants._spline.SplineInterpolant.predict","title":"<code>predict(t_eval)</code>","text":"<p>Evaluate spline interpolation and derivative.</p> <p>Parameters:</p> <ul> <li> <code>t_eval</code>               (<code>torch.Tensor of shape (batch_size, n_eval) or (n_eval,)</code>)           \u2013            <p>Evaluation nodes.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>eval_</code> (              <code>torch.Tensor of shape (batch_size, n_eval, ndim)</code> )          \u2013            <p>Interpolated trajectories.</p> </li> <li> <code>derv_</code> (              <code>torch.Tensor of shape (batch_size, n_eval, ndim)</code> )          \u2013            <p>Derivative trajectories.</p> </li> </ul>"},{"location":"api/pfi/flow/solvers/","title":"solvers","text":""},{"location":"api/pfi/flow/solvers/#pfi.flow.solvers","title":"<code>pfi.flow.solvers</code>","text":""},{"location":"api/pfi/flow/solvers/#pfi.flow.solvers.FM_","title":"<code>FM_(dist, times, interp, net, growth_model=None, fac=1, n_epochs=2000, lr=0.001, alpha_ann=0.5, device='cpu', verbose=True)</code>","text":"<p>Train drift and optional growth models by flow matching.</p> <p>Parameters:</p> <ul> <li> <code>dist</code>               (<code>list of torch.Tensor, length nsnaps</code>)           \u2013            <p><code>dist[k]</code> has shape <code>(n_k, ndim)</code>.</p> </li> <li> <code>times</code>               (<code>torch.Tensor of shape (nsnaps,)</code>)           \u2013            <p>Snapshot times.</p> </li> <li> <code>interp</code>               (<code>object</code>)           \u2013            <p>Interpolant implementing <code>fit(nodes, data)</code> and <code>predict(nodes) -&gt; (x_interp, dx_interp)</code>.</p> </li> <li> <code>net</code>               (<code>Module</code>)           \u2013            <p>Drift model mapping <code>(batch_size, ndim + 1)</code> to <code>(batch_size, ndim)</code>.</p> </li> <li> <code>growth_model</code>               (<code>Module or None</code>, default:                   <code>None</code> )           \u2013            <p>Optional growth model mapping <code>(batch_size, ndim + 1)</code> to <code>(batch_size, 1)</code>.</p> </li> <li> <code>fac</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>Temporal upsampling factor for the uniform grid.</p> </li> <li> <code>n_epochs</code>               (<code>int</code>, default:                   <code>2000</code> )           \u2013            <p>Number of optimization epochs.</p> </li> <li> <code>lr</code>               (<code>float</code>, default:                   <code>1e-3</code> )           \u2013            <p>Learning rate.</p> </li> <li> <code>alpha_ann</code>               (<code>float</code>, default:                   <code>0.5</code> )           \u2013            <p>Exponential averaging factor for adaptive mass-loss weight.</p> </li> <li> <code>device</code>               (<code>str or device</code>, default:                   <code>'cpu'</code> )           \u2013            <p>Training device.</p> </li> <li> <code>verbose</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If <code>True</code>, show progress bars and diagnostics.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>drift_net</code> (              <code>Module</code> )          \u2013            <p>Trained drift model.</p> </li> <li> <code>growth_model</code> (              <code>Module or None</code> )          \u2013            <p>Trained growth model (or <code>None</code> when disabled).</p> </li> </ul>"},{"location":"api/pfi/flow/solvers/#pfi.flow.solvers.interpolate_old2new","title":"<code>interpolate_old2new(Dist, old_nodes, new_nodes)</code>","text":"<p>Interpolate trajectories from one temporal grid to another.</p> <p>Parameters:</p> <ul> <li> <code>Dist</code>               (<code>torch.Tensor of shape (n_old, batch_size, ndim)</code>)           \u2013            <p>Input trajectories at <code>old_nodes</code>.</p> </li> <li> <code>old_nodes</code>               (<code>torch.Tensor of shape (batch_size, n_old)</code>)           \u2013            <p>Original time nodes.</p> </li> <li> <code>new_nodes</code>               (<code>torch.Tensor of shape (batch_size, n_new)</code>)           \u2013            <p>Target time nodes.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>x_interp</code> (              <code>torch.Tensor of shape (n_new, batch_size, ndim)</code> )          \u2013            <p>Interpolated trajectories.</p> </li> </ul>"},{"location":"api/pfi/flow/solvers/_fm/","title":"_fm","text":""},{"location":"api/pfi/flow/solvers/_fm/#pfi.flow.solvers._fm","title":"<code>pfi.flow.solvers._fm</code>","text":"<p>Flow-matching solver and helper routines.</p>"},{"location":"api/pfi/flow/solvers/_fm/#pfi.flow.solvers._fm.FM_","title":"<code>FM_(dist, times, interp, net, growth_model=None, fac=1, n_epochs=2000, lr=0.001, alpha_ann=0.5, device='cpu', verbose=True)</code>","text":"<p>Train drift and optional growth models by flow matching.</p> <p>Parameters:</p> <ul> <li> <code>dist</code>               (<code>list of torch.Tensor, length nsnaps</code>)           \u2013            <p><code>dist[k]</code> has shape <code>(n_k, ndim)</code>.</p> </li> <li> <code>times</code>               (<code>torch.Tensor of shape (nsnaps,)</code>)           \u2013            <p>Snapshot times.</p> </li> <li> <code>interp</code>               (<code>object</code>)           \u2013            <p>Interpolant implementing <code>fit(nodes, data)</code> and <code>predict(nodes) -&gt; (x_interp, dx_interp)</code>.</p> </li> <li> <code>net</code>               (<code>Module</code>)           \u2013            <p>Drift model mapping <code>(batch_size, ndim + 1)</code> to <code>(batch_size, ndim)</code>.</p> </li> <li> <code>growth_model</code>               (<code>Module or None</code>, default:                   <code>None</code> )           \u2013            <p>Optional growth model mapping <code>(batch_size, ndim + 1)</code> to <code>(batch_size, 1)</code>.</p> </li> <li> <code>fac</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>Temporal upsampling factor for the uniform grid.</p> </li> <li> <code>n_epochs</code>               (<code>int</code>, default:                   <code>2000</code> )           \u2013            <p>Number of optimization epochs.</p> </li> <li> <code>lr</code>               (<code>float</code>, default:                   <code>1e-3</code> )           \u2013            <p>Learning rate.</p> </li> <li> <code>alpha_ann</code>               (<code>float</code>, default:                   <code>0.5</code> )           \u2013            <p>Exponential averaging factor for adaptive mass-loss weight.</p> </li> <li> <code>device</code>               (<code>str or device</code>, default:                   <code>'cpu'</code> )           \u2013            <p>Training device.</p> </li> <li> <code>verbose</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If <code>True</code>, show progress bars and diagnostics.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>drift_net</code> (              <code>Module</code> )          \u2013            <p>Trained drift model.</p> </li> <li> <code>growth_model</code> (              <code>Module or None</code> )          \u2013            <p>Trained growth model (or <code>None</code> when disabled).</p> </li> </ul>"},{"location":"api/pfi/flow/solvers/_fm/#pfi.flow.solvers._fm.compute_conditional_distributions","title":"<code>compute_conditional_distributions(interp, Dist, batch_size, weights, nodes_fit, nodes_eval, device='cpu', sigma=0.001)</code>","text":"<p>Build conditional training pairs for weighted flow matching.</p> <p>Parameters:</p> <ul> <li> <code>interp</code>               (<code>object</code>)           \u2013            <p>Interpolant implementing <code>fit</code> and <code>predict</code>.</p> </li> <li> <code>Dist</code>               (<code>torch.Tensor of shape (n_nodes, nsamples, ndim)</code>)           \u2013            <p>OT trajectories on a temporal grid.</p> </li> <li> <code>batch_size</code>               (<code>int</code>)           \u2013            <p>Number of trajectories sampled per iteration.</p> </li> <li> <code>weights</code>               (<code>torch.Tensor of shape (n_nodes, nsamples)</code>)           \u2013            <p>Per-trajectory importance weights.</p> </li> <li> <code>nodes_fit</code>               (<code>torch.Tensor of shape (batch_size, n_nodes)</code>)           \u2013            <p>Nodes used to fit interpolants.</p> </li> <li> <code>nodes_eval</code>               (<code>torch.Tensor of shape (batch_size, n_eval)</code>)           \u2013            <p>Nodes used to evaluate interpolants.</p> </li> <li> <code>device</code>               (<code>str or device</code>, default:                   <code>'cpu'</code> )           \u2013            <p>Device used for output tensors.</p> </li> <li> <code>sigma</code>               (<code>float</code>, default:                   <code>0.001</code> )           \u2013            <p>Gaussian perturbation added to interpolated positions.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>xtrain</code> (              <code>torch.Tensor of shape (batch_size * n_eval, ndim + 1)</code> )          \u2013            <p>Inputs for drift training (state + time).</p> </li> <li> <code>ytrain</code> (              <code>torch.Tensor of shape (batch_size * n_eval, ndim)</code> )          \u2013            <p>Target velocities.</p> </li> <li> <code>weights</code> (              <code>torch.Tensor of shape (batch_size, n_nodes)</code> )          \u2013            <p>Sampled weights aligned with <code>xtrain</code>/<code>ytrain</code>.</p> </li> </ul>"},{"location":"api/pfi/flow/solvers/_fm/#pfi.flow.solvers._fm.interpolate_old2new","title":"<code>interpolate_old2new(Dist, old_nodes, new_nodes)</code>","text":"<p>Interpolate trajectories from one temporal grid to another.</p> <p>Parameters:</p> <ul> <li> <code>Dist</code>               (<code>torch.Tensor of shape (n_old, batch_size, ndim)</code>)           \u2013            <p>Input trajectories at <code>old_nodes</code>.</p> </li> <li> <code>old_nodes</code>               (<code>torch.Tensor of shape (batch_size, n_old)</code>)           \u2013            <p>Original time nodes.</p> </li> <li> <code>new_nodes</code>               (<code>torch.Tensor of shape (batch_size, n_new)</code>)           \u2013            <p>Target time nodes.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>x_interp</code> (              <code>torch.Tensor of shape (n_new, batch_size, ndim)</code> )          \u2013            <p>Interpolated trajectories.</p> </li> </ul>"},{"location":"api/pfi/flow/solvers/_ode/","title":"_ode","text":""},{"location":"api/pfi/flow/solvers/_ode/#pfi.flow.solvers._ode","title":"<code>pfi.flow.solvers._ode</code>","text":"<p>Functions which should implement Unbalanced PFI</p>"},{"location":"api/pfi/flow/solvers/_sde/","title":"_sde","text":""},{"location":"api/pfi/flow/solvers/_sde/#pfi.flow.solvers._sde","title":"<code>pfi.flow.solvers._sde</code>","text":"<p>Functions which should implement PFI with SDEs (bad idea)</p>"},{"location":"api/pfi/score/","title":"score","text":""},{"location":"api/pfi/score/#pfi.score","title":"<code>pfi.score</code>","text":"<p>Public score-estimation APIs and solver modules.</p> <p>This submodule exposes the score matching estimator alongside analytical score models and solver backends.</p>"},{"location":"api/pfi/score/#pfi.score.ScoreMatching","title":"<code>ScoreMatching(model, solver='dsm', solver_kwargs=None, device='cpu')</code>","text":"<p>Estimate score functions from snapshot data.</p> <p>Parameters:</p> <ul> <li> <code>model</code>               (<code>Module</code>)           \u2013            <p>Score model (dimensions of input change depending on solver)</p> </li> <li> <code>solver</code>               (<code>dsm</code>, default:                   <code>'dsm'</code> )           \u2013            <p>Solver backend.</p> </li> <li> <code>solver_kwargs</code>               (<code>dict</code>, default:                   <code>None</code> )           \u2013            <p>Extra keyword arguments passed to the selected solver.</p> </li> <li> <code>device</code>               (<code>str or device</code>, default:                   <code>'cpu'</code> )           \u2013            <p>Device used for training and inference.</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>Ndim_</code>               (<code>int</code>)           \u2013            <p>Inferred state dimension, set during <code>fit</code>.</p> </li> <li> <code>times_</code>               (<code>ndarray of shape (n_times,)</code>)           \u2013            <p>Sorted unique training times, set during <code>fit</code>.</p> </li> <li> <code>model_</code>               (<code>Module</code>)           \u2013            <p>Fitted score model used at inference time, set during <code>fit</code>. The input of this fitted model is (x,t), dimension ndim + 1.</p> </li> </ul>"},{"location":"api/pfi/score/#pfi.score.ScoreMatching.fit","title":"<code>fit(X, y=None)</code>","text":"<p>Fit the score estimator on time-augmented data.</p> <p>Parameters:</p> <ul> <li> <code>X</code>               (<code>ndarray of shape (n_samples, ndim + 1)</code>)           \u2013            <p>Input data where the last column contains time.</p> </li> <li> <code>y</code>               (<code>None</code>, default:                   <code>None</code> )           \u2013            <p>Ignored. Present for estimator API compatibility.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>self</code> (              <code>ScoreMatching</code> )          \u2013            <p>Fitted estimator.</p> </li> </ul>"},{"location":"api/pfi/score/#pfi.score.ScoreMatching.predict","title":"<code>predict(X)</code>","text":"<p>Predict score vectors for input samples.</p> <p>Parameters:</p> <ul> <li> <code>X</code>               (<code>array-like of shape (n_samples, ndim + 1)</code>)           \u2013            <p>Inputs containing state and time columns. The internal noise-level feature is inserted by <code>model_</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>score</code> (              <code>ndarray of shape (n_samples, ndim)</code> )          \u2013            <p>Predicted score vectors.</p> </li> </ul>"},{"location":"api/pfi/score/#pfi.score.ScoreMatching.sample","title":"<code>sample(X, nsamples=None, maxiter=100)</code>","text":"<p>Generate samples using the fitted score model.</p> <p>Parameters:</p> <ul> <li> <code>X</code>               (<code>ndarray of shape of shape (n_samples, ndim + 1)</code>)           \u2013            <p>Conditioning samples with time in the last column.</p> </li> <li> <code>nsamples</code>               (<code>int</code>, default:                   <code>None</code> )           \u2013            <p>Number of generated samples. If <code>None</code>, uses <code>X.shape[0]</code>.</p> </li> <li> <code>maxiter</code>               (<code>int</code>, default:                   <code>100</code> )           \u2013            <p>Number of Langevin updates per noise level.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>gen</code> (              <code>ndarray of shape (nsamples, ndim)</code> )          \u2013            <p>Generated samples.</p> </li> </ul>"},{"location":"api/pfi/score/#pfi.score.ScoreMatching.score","title":"<code>score(X, y=None, maxiter=100)</code>","text":"<p>Compute per-time energy distance between generated and observed data.</p> <p>Parameters:</p> <ul> <li> <code>X</code>               (<code>ndarray of shape (n_samples, ndim + 1)</code>)           \u2013            <p>Input data with time in the last column.</p> </li> <li> <code>y</code>               (<code>None</code>, default:                   <code>None</code> )           \u2013            <p>Ignored. Present for estimator API compatibility.</p> </li> <li> <code>maxiter</code>               (<code>int</code>, default:                   <code>100</code> )           \u2013            <p>Number of Langevin updates used during sampling.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>scores</code> (              <code>ndarray of shape (n_times,)</code> )          \u2013            <p>Energy distance at each unique time in <code>X</code>.</p> </li> </ul>"},{"location":"api/pfi/score/_base/","title":"_base","text":""},{"location":"api/pfi/score/_base/#pfi.score._base","title":"<code>pfi.score._base</code>","text":"<p>Score-matching estimator interface and evaluation utilities.</p>"},{"location":"api/pfi/score/_base/#pfi.score._base.ScoreMatching","title":"<code>ScoreMatching(model, solver='dsm', solver_kwargs=None, device='cpu')</code>","text":"<p>Estimate score functions from snapshot data.</p> <p>Parameters:</p> <ul> <li> <code>model</code>               (<code>Module</code>)           \u2013            <p>Score model (dimensions of input change depending on solver)</p> </li> <li> <code>solver</code>               (<code>dsm</code>, default:                   <code>'dsm'</code> )           \u2013            <p>Solver backend.</p> </li> <li> <code>solver_kwargs</code>               (<code>dict</code>, default:                   <code>None</code> )           \u2013            <p>Extra keyword arguments passed to the selected solver.</p> </li> <li> <code>device</code>               (<code>str or device</code>, default:                   <code>'cpu'</code> )           \u2013            <p>Device used for training and inference.</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>Ndim_</code>               (<code>int</code>)           \u2013            <p>Inferred state dimension, set during <code>fit</code>.</p> </li> <li> <code>times_</code>               (<code>ndarray of shape (n_times,)</code>)           \u2013            <p>Sorted unique training times, set during <code>fit</code>.</p> </li> <li> <code>model_</code>               (<code>Module</code>)           \u2013            <p>Fitted score model used at inference time, set during <code>fit</code>. The input of this fitted model is (x,t), dimension ndim + 1.</p> </li> </ul>"},{"location":"api/pfi/score/_base/#pfi.score._base.ScoreMatching.fit","title":"<code>fit(X, y=None)</code>","text":"<p>Fit the score estimator on time-augmented data.</p> <p>Parameters:</p> <ul> <li> <code>X</code>               (<code>ndarray of shape (n_samples, ndim + 1)</code>)           \u2013            <p>Input data where the last column contains time.</p> </li> <li> <code>y</code>               (<code>None</code>, default:                   <code>None</code> )           \u2013            <p>Ignored. Present for estimator API compatibility.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>self</code> (              <code>ScoreMatching</code> )          \u2013            <p>Fitted estimator.</p> </li> </ul>"},{"location":"api/pfi/score/_base/#pfi.score._base.ScoreMatching.predict","title":"<code>predict(X)</code>","text":"<p>Predict score vectors for input samples.</p> <p>Parameters:</p> <ul> <li> <code>X</code>               (<code>array-like of shape (n_samples, ndim + 1)</code>)           \u2013            <p>Inputs containing state and time columns. The internal noise-level feature is inserted by <code>model_</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>score</code> (              <code>ndarray of shape (n_samples, ndim)</code> )          \u2013            <p>Predicted score vectors.</p> </li> </ul>"},{"location":"api/pfi/score/_base/#pfi.score._base.ScoreMatching.sample","title":"<code>sample(X, nsamples=None, maxiter=100)</code>","text":"<p>Generate samples using the fitted score model.</p> <p>Parameters:</p> <ul> <li> <code>X</code>               (<code>ndarray of shape of shape (n_samples, ndim + 1)</code>)           \u2013            <p>Conditioning samples with time in the last column.</p> </li> <li> <code>nsamples</code>               (<code>int</code>, default:                   <code>None</code> )           \u2013            <p>Number of generated samples. If <code>None</code>, uses <code>X.shape[0]</code>.</p> </li> <li> <code>maxiter</code>               (<code>int</code>, default:                   <code>100</code> )           \u2013            <p>Number of Langevin updates per noise level.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>gen</code> (              <code>ndarray of shape (nsamples, ndim)</code> )          \u2013            <p>Generated samples.</p> </li> </ul>"},{"location":"api/pfi/score/_base/#pfi.score._base.ScoreMatching.score","title":"<code>score(X, y=None, maxiter=100)</code>","text":"<p>Compute per-time energy distance between generated and observed data.</p> <p>Parameters:</p> <ul> <li> <code>X</code>               (<code>ndarray of shape (n_samples, ndim + 1)</code>)           \u2013            <p>Input data with time in the last column.</p> </li> <li> <code>y</code>               (<code>None</code>, default:                   <code>None</code> )           \u2013            <p>Ignored. Present for estimator API compatibility.</p> </li> <li> <code>maxiter</code>               (<code>int</code>, default:                   <code>100</code> )           \u2013            <p>Number of Langevin updates used during sampling.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>scores</code> (              <code>ndarray of shape (n_times,)</code> )          \u2013            <p>Energy distance at each unique time in <code>X</code>.</p> </li> </ul>"},{"location":"api/pfi/score/models/","title":"models","text":""},{"location":"api/pfi/score/models/#pfi.score.models","title":"<code>pfi.score.models</code>","text":"<p>Analytical score models used by score-matching and flow estimators.</p>"},{"location":"api/pfi/score/models/#pfi.score.models.OUScore","title":"<code>OUScore(B, m0, S0, D)</code>","text":"<p>               Bases: <code>Module</code></p> <p>Analytical score function for Gaussian Ornstein-Uhlenbeck dynamics.</p> <p>Parameters:</p> <ul> <li> <code>B</code>               (<code>torch.Tensor of shape (ndim, ndim)</code>)           \u2013            <p>Drift matrix.</p> </li> <li> <code>m0</code>               (<code>torch.Tensor of shape (ndim,)</code>)           \u2013            <p>Initial mean.</p> </li> <li> <code>S0</code>               (<code>torch.Tensor of shape (ndim, ndim)</code>)           \u2013            <p>Initial covariance matrix.</p> </li> <li> <code>D</code>               (<code>torch.Tensor of shape (ndim, ndim)</code>)           \u2013            <p>Diffusion matrix.</p> </li> </ul>"},{"location":"api/pfi/score/solvers/","title":"solvers","text":""},{"location":"api/pfi/score/solvers/#pfi.score.solvers","title":"<code>pfi.score.solvers</code>","text":""},{"location":"api/pfi/score/solvers/#pfi.score.solvers.DSM_","title":"<code>DSM_(dist, times, net, L=10, n_epochs=2000, bs=None, adp_flag=0, lr=0.0001, device='cpu', verbose=True)</code>","text":"<p>Train a score network with denoising score matching.</p> <p>Parameters:</p> <ul> <li> <code>dist</code>               (<code>list of torch.Tensor, length nsnaps</code>)           \u2013            <p><code>dist[k]</code> has shape <code>(n_k, ndim)</code>.</p> </li> <li> <code>times</code>               (<code>torch.Tensor of shape (nsnaps,)</code>)           \u2013            <p>Snapshot times.</p> </li> <li> <code>net</code>               (<code>Module</code>)           \u2013            <p>Score network that accepts inputs of shape <code>(nsnaps, L, batch_size, ndim + 2)</code> after batching.</p> </li> <li> <code>L</code>               (<code>int</code>, default:                   <code>10</code> )           \u2013            <p>Number of noise levels.</p> </li> <li> <code>n_epochs</code>               (<code>int</code>, default:                   <code>2000</code> )           \u2013            <p>Number of optimization epochs.</p> </li> <li> <code>bs</code>               (<code>int or None</code>, default:                   <code>None</code> )           \u2013            <p>Mini-batch size over sample dimension. If <code>None</code>, uses all samples.</p> </li> <li> <code>adp_flag</code>               (<code>int</code>, default:                   <code>0</code> )           \u2013            <p>If set to <code>1</code>, enable adaptive per-time weighting.</p> </li> <li> <code>lr</code>               (<code>float</code>, default:                   <code>1e-4</code> )           \u2013            <p>Learning rate.</p> </li> <li> <code>device</code>               (<code>str or device</code>, default:                   <code>'cpu'</code> )           \u2013            <p>Training device.</p> </li> <li> <code>verbose</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If <code>True</code>, show progress bars and diagnostics.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>net</code> (              <code>Module</code> )          \u2013            <p>Trained score network.</p> </li> </ul>"},{"location":"api/pfi/score/solvers/#pfi.score.solvers.generate_data_DSM","title":"<code>generate_data_DSM(maxiter, infNet, nsamples, init_, time_, L, ndim, device)</code>","text":"<p>Sample from a trained DSM model using annealed Langevin dynamics.</p> <p>Parameters:</p> <ul> <li> <code>maxiter</code>               (<code>int</code>)           \u2013            <p>Number of Langevin steps per noise level.</p> </li> <li> <code>infNet</code>               (<code>Module</code>)           \u2013            <p>Trained score model.</p> </li> <li> <code>nsamples</code>               (<code>int</code>)           \u2013            <p>Number of samples to generate.</p> </li> <li> <code>init_</code>               (<code>ndarray of shape (nsamples, ndim + 2)</code>)           \u2013            <p>Initial states including noise-level and time columns.</p> </li> <li> <code>time_</code>               (<code>float</code>)           \u2013            <p>Time value assigned to all generated samples.</p> </li> <li> <code>L</code>               (<code>int</code>)           \u2013            <p>Number of noise levels.</p> </li> <li> <code>ndim</code>               (<code>int</code>)           \u2013            <p>State dimension.</p> </li> <li> <code>device</code>               (<code>str or device</code>)           \u2013            <p>Device used for generation.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>sol</code> (              <code>ndarray of shape (nsamples, ndim + 2)</code> )          \u2013            <p>Generated states including auxiliary columns.</p> </li> <li> <code>gen_mean</code> (              <code>torch.Tensor of shape (ndim,)</code> )          \u2013            <p>Mean of generated state coordinates.</p> </li> </ul>"},{"location":"api/pfi/score/solvers/#pfi.score.solvers.generate_noisy_training_data_batch","title":"<code>generate_noisy_training_data_batch(Dist, ndim, tp, L, nsamples, nsnaps, device)</code>","text":"<p>Generate noisy DSM training inputs and normalization statistics.</p> <p>Parameters:</p> <ul> <li> <code>Dist</code>               (<code>torch.Tensor or ndarray of shape (nsnaps, nsamples, ndim)</code>)           \u2013            <p>Snapshot samples.</p> </li> <li> <code>ndim</code>               (<code>int</code>)           \u2013            <p>State dimension.</p> </li> <li> <code>tp</code>               (<code>array-like of shape (nsnaps,)</code>)           \u2013            <p>Snapshot times.</p> </li> <li> <code>L</code>               (<code>int</code>)           \u2013            <p>Number of noise levels.</p> </li> <li> <code>nsamples</code>               (<code>int</code>)           \u2013            <p>Number of samples per snapshot.</p> </li> <li> <code>nsnaps</code>               (<code>int</code>)           \u2013            <p>Number of snapshots.</p> </li> <li> <code>device</code>               (<code>str or device</code>)           \u2013            <p>Target device for returned tensors.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>x_train</code> (              <code>torch.Tensor of shape (nsnaps, L, nsamples, ndim + 2)</code> )          \u2013            <p>Noisy training inputs with appended noise level and time.</p> </li> <li> <code>x_data</code> (              <code>torch.Tensor of shape (nsnaps, nsamples, ndim)</code> )          \u2013            <p>Clean data tensor.</p> </li> <li> <code>x_mean</code> (              <code>torch.Tensor of shape (1, ndim + 2)</code> )          \u2013            <p>Feature-wise mean used for input normalization.</p> </li> <li> <code>x_std</code> (              <code>torch.Tensor of shape (1, ndim + 2)</code> )          \u2013            <p>Feature-wise standard deviation used for input normalization.</p> </li> <li> <code>sigma</code> (              <code>ndarray of shape (L,)</code> )          \u2013            <p>Noise schedule.</p> </li> </ul>"},{"location":"api/pfi/score/solvers/_dsm/","title":"_dsm","text":""},{"location":"api/pfi/score/solvers/_dsm/#pfi.score.solvers._dsm","title":"<code>pfi.score.solvers._dsm</code>","text":"<p>Denoising score-matching (DSM) solvers and sampling utilities.</p>"},{"location":"api/pfi/score/solvers/_dsm/#pfi.score.solvers._dsm.DSM_","title":"<code>DSM_(dist, times, net, L=10, n_epochs=2000, bs=None, adp_flag=0, lr=0.0001, device='cpu', verbose=True)</code>","text":"<p>Train a score network with denoising score matching.</p> <p>Parameters:</p> <ul> <li> <code>dist</code>               (<code>list of torch.Tensor, length nsnaps</code>)           \u2013            <p><code>dist[k]</code> has shape <code>(n_k, ndim)</code>.</p> </li> <li> <code>times</code>               (<code>torch.Tensor of shape (nsnaps,)</code>)           \u2013            <p>Snapshot times.</p> </li> <li> <code>net</code>               (<code>Module</code>)           \u2013            <p>Score network that accepts inputs of shape <code>(nsnaps, L, batch_size, ndim + 2)</code> after batching.</p> </li> <li> <code>L</code>               (<code>int</code>, default:                   <code>10</code> )           \u2013            <p>Number of noise levels.</p> </li> <li> <code>n_epochs</code>               (<code>int</code>, default:                   <code>2000</code> )           \u2013            <p>Number of optimization epochs.</p> </li> <li> <code>bs</code>               (<code>int or None</code>, default:                   <code>None</code> )           \u2013            <p>Mini-batch size over sample dimension. If <code>None</code>, uses all samples.</p> </li> <li> <code>adp_flag</code>               (<code>int</code>, default:                   <code>0</code> )           \u2013            <p>If set to <code>1</code>, enable adaptive per-time weighting.</p> </li> <li> <code>lr</code>               (<code>float</code>, default:                   <code>1e-4</code> )           \u2013            <p>Learning rate.</p> </li> <li> <code>device</code>               (<code>str or device</code>, default:                   <code>'cpu'</code> )           \u2013            <p>Training device.</p> </li> <li> <code>verbose</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If <code>True</code>, show progress bars and diagnostics.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>net</code> (              <code>Module</code> )          \u2013            <p>Trained score network.</p> </li> </ul>"},{"location":"api/pfi/score/solvers/_dsm/#pfi.score.solvers._dsm.generate_data_DSM","title":"<code>generate_data_DSM(maxiter, infNet, nsamples, init_, time_, L, ndim, device)</code>","text":"<p>Sample from a trained DSM model using annealed Langevin dynamics.</p> <p>Parameters:</p> <ul> <li> <code>maxiter</code>               (<code>int</code>)           \u2013            <p>Number of Langevin steps per noise level.</p> </li> <li> <code>infNet</code>               (<code>Module</code>)           \u2013            <p>Trained score model.</p> </li> <li> <code>nsamples</code>               (<code>int</code>)           \u2013            <p>Number of samples to generate.</p> </li> <li> <code>init_</code>               (<code>ndarray of shape (nsamples, ndim + 2)</code>)           \u2013            <p>Initial states including noise-level and time columns.</p> </li> <li> <code>time_</code>               (<code>float</code>)           \u2013            <p>Time value assigned to all generated samples.</p> </li> <li> <code>L</code>               (<code>int</code>)           \u2013            <p>Number of noise levels.</p> </li> <li> <code>ndim</code>               (<code>int</code>)           \u2013            <p>State dimension.</p> </li> <li> <code>device</code>               (<code>str or device</code>)           \u2013            <p>Device used for generation.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>sol</code> (              <code>ndarray of shape (nsamples, ndim + 2)</code> )          \u2013            <p>Generated states including auxiliary columns.</p> </li> <li> <code>gen_mean</code> (              <code>torch.Tensor of shape (ndim,)</code> )          \u2013            <p>Mean of generated state coordinates.</p> </li> </ul>"},{"location":"api/pfi/score/solvers/_dsm/#pfi.score.solvers._dsm.generate_noisy_training_data_batch","title":"<code>generate_noisy_training_data_batch(Dist, ndim, tp, L, nsamples, nsnaps, device)</code>","text":"<p>Generate noisy DSM training inputs and normalization statistics.</p> <p>Parameters:</p> <ul> <li> <code>Dist</code>               (<code>torch.Tensor or ndarray of shape (nsnaps, nsamples, ndim)</code>)           \u2013            <p>Snapshot samples.</p> </li> <li> <code>ndim</code>               (<code>int</code>)           \u2013            <p>State dimension.</p> </li> <li> <code>tp</code>               (<code>array-like of shape (nsnaps,)</code>)           \u2013            <p>Snapshot times.</p> </li> <li> <code>L</code>               (<code>int</code>)           \u2013            <p>Number of noise levels.</p> </li> <li> <code>nsamples</code>               (<code>int</code>)           \u2013            <p>Number of samples per snapshot.</p> </li> <li> <code>nsnaps</code>               (<code>int</code>)           \u2013            <p>Number of snapshots.</p> </li> <li> <code>device</code>               (<code>str or device</code>)           \u2013            <p>Target device for returned tensors.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>x_train</code> (              <code>torch.Tensor of shape (nsnaps, L, nsamples, ndim + 2)</code> )          \u2013            <p>Noisy training inputs with appended noise level and time.</p> </li> <li> <code>x_data</code> (              <code>torch.Tensor of shape (nsnaps, nsamples, ndim)</code> )          \u2013            <p>Clean data tensor.</p> </li> <li> <code>x_mean</code> (              <code>torch.Tensor of shape (1, ndim + 2)</code> )          \u2013            <p>Feature-wise mean used for input normalization.</p> </li> <li> <code>x_std</code> (              <code>torch.Tensor of shape (1, ndim + 2)</code> )          \u2013            <p>Feature-wise standard deviation used for input normalization.</p> </li> <li> <code>sigma</code> (              <code>ndarray of shape (L,)</code> )          \u2013            <p>Noise schedule.</p> </li> </ul>"},{"location":"api/pfi/score/solvers/_dsm/#pfi.score.solvers._dsm.geometric_sequence","title":"<code>geometric_sequence(L)</code>","text":"<p>Build the geometric noise schedule used by DSM.</p> <p>Parameters:</p> <ul> <li> <code>L</code>               (<code>int</code>)           \u2013            <p>Number of noise levels.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>sigma</code> (              <code>ndarray of shape (L,)</code> )          \u2013            <p>Geometrically decaying standard deviations.</p> </li> </ul>"},{"location":"api/pfi/score/solvers/_ssm/","title":"_ssm","text":""},{"location":"api/pfi/score/solvers/_ssm/#pfi.score.solvers._ssm","title":"<code>pfi.score.solvers._ssm</code>","text":"<p>Functions that should implement sliced score matching</p>"},{"location":"api/pfi/utils/","title":"utils","text":""},{"location":"api/pfi/utils/#pfi.utils","title":"<code>pfi.utils</code>","text":"<p>Public utility exports for simulations, data handling, and neural nets.</p> <p>This submodule collects helper functions and classes used across the package.</p>"},{"location":"api/pfi/utils/#pfi.utils.BatchNorm","title":"<code>BatchNorm(mean, std)</code>","text":"<p>               Bases: <code>object</code></p> <p>Simple affine normalizer <code>(x - mean) / std</code>.</p> <p>Parameters:</p> <ul> <li> <code>mean</code>               (<code>float or torch.Tensor of shape (n_features,) or (1, n_features)</code>)           \u2013            <p>Feature-wise mean.</p> </li> <li> <code>std</code>               (<code>float or torch.Tensor of shape (n_features,) or (1, n_features)</code>)           \u2013            <p>Feature-wise standard deviation.</p> </li> </ul>"},{"location":"api/pfi/utils/#pfi.utils.DNN","title":"<code>DNN(sizes, mean=0, std=1, seed=0, activation=nn.Tanh())</code>","text":"<p>               Bases: <code>Module</code></p> <p>Fully-connected network with optional feature normalization.</p> <p>Parameters:</p> <ul> <li> <code>sizes</code>               (<code>list of int</code>)           \u2013            <p>Layer sizes including input and output dimensions.</p> </li> <li> <code>mean</code>               (<code>float or Tensor</code>, default:                   <code>0</code> )           \u2013            <p>Initial mean used by the internal normalizer.</p> </li> <li> <code>std</code>               (<code>float or Tensor</code>, default:                   <code>1</code> )           \u2013            <p>Initial standard deviation used by the internal normalizer.</p> </li> <li> <code>seed</code>               (<code>int</code>, default:                   <code>0</code> )           \u2013            <p>Random seed for layer initialization.</p> </li> <li> <code>activation</code>               (<code>Module</code>, default:                   <code>torch.nn.Tanh()</code> )           \u2013            <p>Hidden activation module.</p> </li> </ul>"},{"location":"api/pfi/utils/#pfi.utils.DNN.set_scales","title":"<code>set_scales(mean, std)</code>","text":"<p>Update normalization statistics.</p> <p>Parameters:</p> <ul> <li> <code>mean</code>               (<code>torch.Tensor of shape (1, n_features)</code>)           \u2013            <p>New feature means.</p> </li> <li> <code>std</code>               (<code>torch.Tensor of shape (1, n_features)</code>)           \u2013            <p>New feature standard deviations.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>self</code> (              <code>DNN</code> )          \u2013            <p>Estimator instance.</p> </li> </ul>"},{"location":"api/pfi/utils/#pfi.utils.FastTensorDataLoader","title":"<code>FastTensorDataLoader(*tensors, batch_size=32, shuffle=False)</code>","text":"<p>Lightweight mini-batch iterator over in-memory tensors.</p> <p>Parameters:</p> <ul> <li> <code>*tensors</code>               (<code>tuple of torch.Tensor</code>, default:                   <code>()</code> )           \u2013            <p>Tensors with matching first dimension.</p> </li> <li> <code>batch_size</code>               (<code>int</code>, default:                   <code>32</code> )           \u2013            <p>Number of samples per yielded batch.</p> </li> <li> <code>shuffle</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If <code>True</code>, shuffle samples at each iteration.</p> </li> </ul>"},{"location":"api/pfi/utils/#pfi.utils.FreezeVarDNN","title":"<code>FreezeVarDNN(dnn, var_index, var_value)</code>","text":"<p>               Bases: <code>Module</code></p> <p>Wrapper that fixes one input feature to a constant before inference.</p> <p>Parameters:</p> <ul> <li> <code>dnn</code>               (<code>Module</code>)           \u2013            <p>Base network receiving <code>n_features</code> inputs.</p> </li> <li> <code>var_index</code>               (<code>int</code>)           \u2013            <p>Index of the feature to overwrite.</p> </li> <li> <code>var_value</code>               (<code>float</code>)           \u2013            <p>Constant value assigned to that feature.</p> </li> </ul>"},{"location":"api/pfi/utils/#pfi.utils.LayerNoWN","title":"<code>LayerNoWN(in_features, out_features, seed, activation)</code>","text":"<p>               Bases: <code>Module</code></p> <p>Linear layer with Xavier initialization and no weight normalization.</p> <p>Parameters:</p> <ul> <li> <code>in_features</code>               (<code>int</code>)           \u2013            <p>Input feature dimension.</p> </li> <li> <code>out_features</code>               (<code>int</code>)           \u2013            <p>Output feature dimension.</p> </li> <li> <code>seed</code>               (<code>int</code>)           \u2013            <p>Random seed used for initialization.</p> </li> <li> <code>activation</code>               (<code>Module</code>)           \u2013            <p>Activation used in surrounding network to set initialization gain.</p> </li> </ul>"},{"location":"api/pfi/utils/#pfi.utils.SpectralNormDNN","title":"<code>SpectralNormDNN(sizes, mean=0, std=1, seed=0, activation=nn.Tanh())</code>","text":"<p>               Bases: <code>Module</code></p> <p>Fully-connected network with spectral normalization on hidden layers.</p> <p>Parameters:</p> <ul> <li> <code>sizes</code>               (<code>list of int</code>)           \u2013            <p>Layer sizes including input and output dimensions.</p> </li> <li> <code>mean</code>               (<code>float or Tensor</code>, default:                   <code>0</code> )           \u2013            <p>Initial mean used by the internal normalizer.</p> </li> <li> <code>std</code>               (<code>float or Tensor</code>, default:                   <code>1</code> )           \u2013            <p>Initial standard deviation used by the internal normalizer.</p> </li> <li> <code>seed</code>               (<code>int</code>, default:                   <code>0</code> )           \u2013            <p>Random seed for layer initialization.</p> </li> <li> <code>activation</code>               (<code>Module</code>, default:                   <code>torch.nn.Tanh()</code> )           \u2013            <p>Hidden activation module.</p> </li> </ul>"},{"location":"api/pfi/utils/#pfi.utils.SpectralNormDNN.set_scales","title":"<code>set_scales(mean, std)</code>","text":"<p>Update normalization statistics.</p> <p>Parameters:</p> <ul> <li> <code>mean</code>               (<code>torch.Tensor of shape (1, n_features)</code>)           \u2013            <p>New feature means.</p> </li> <li> <code>std</code>               (<code>torch.Tensor of shape (1, n_features)</code>)           \u2013            <p>New feature standard deviations.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>self</code> (              <code>SpectralNormDNN</code> )          \u2013            <p>Estimator instance.</p> </li> </ul>"},{"location":"api/pfi/utils/#pfi.utils.X_from_snapshots","title":"<code>X_from_snapshots(snaps, times)</code>","text":"<p>Stack snapshots into a single array with appended time column.</p> <p>Parameters:</p> <ul> <li> <code>snaps</code>               (<code>list of ndarray, length n_snaps</code>)           \u2013            <p><code>snaps[k]</code> has shape <code>(n_k, ndim)</code>.</p> </li> <li> <code>times</code>               (<code>array-like of shape (n_snaps,)</code>)           \u2013            <p>Snapshot times aligned with <code>snaps</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>X</code> (              <code>ndarray of shape (sum_k n_k, ndim + 1)</code> )          \u2013            <p>Concatenated dataset where last column stores time.</p> </li> </ul>"},{"location":"api/pfi/utils/#pfi.utils.divergence","title":"<code>divergence(field, x)</code>","text":"<p>Compute coordinate-wise divergence terms of a vector field.</p> <p>Parameters:</p> <ul> <li> <code>field</code>               (<code>torch.Tensor of shape (batch_size, ndim)</code>)           \u2013            <p>Vector field evaluated at <code>x</code>.</p> </li> <li> <code>x</code>               (<code>torch.Tensor of shape (batch_size, ndim)</code>)           \u2013            <p>Input points with gradient tracking enabled.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>div</code> (              <code>torch.Tensor of shape (batch_size, ndim)</code> )          \u2013            <p>Diagonal Jacobian terms, one per coordinate.</p> </li> </ul>"},{"location":"api/pfi/utils/#pfi.utils.g_rate","title":"<code>g_rate(x1, x2, gr)</code>","text":"<p>Compute the cell growth rate used in the toggle-switch simulator.</p> <p>Parameters:</p> <ul> <li> <code>x1</code>               (<code>ndarray of shape (n_samples,)</code>)           \u2013            <p>First coordinate of the state.</p> </li> <li> <code>x2</code>               (<code>ndarray of shape (n_samples,)</code>)           \u2013            <p>Second coordinate of the state.</p> </li> <li> <code>gr</code>               (<code>float</code>)           \u2013            <p>Growth-rate scale.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>rate</code> (              <code>ndarray of shape (n_samples,)</code> )          \u2013            <p>Growth rate for each sample.</p> </li> </ul>"},{"location":"api/pfi/utils/#pfi.utils.simulate_ornstein_uhlenbeck","title":"<code>simulate_ornstein_uhlenbeck(Om, D, m0, S0, nsamples, ndim, Dt, K, dt=0.006)</code>","text":"<p>Simulate snapshots from a linear Ornstein-Uhlenbeck process.</p> <p>Parameters:</p> <ul> <li> <code>Om</code>               (<code>ndarray of shape (ndim, ndim)</code>)           \u2013            <p>Drift matrix.</p> </li> <li> <code>D</code>               (<code>ndarray of shape (ndim, ndim)</code>)           \u2013            <p>Diffusion matrix.</p> </li> <li> <code>m0</code>               (<code>ndarray of shape (ndim,)</code>)           \u2013            <p>Mean of the initial Gaussian distribution.</p> </li> <li> <code>S0</code>               (<code>float</code>)           \u2013            <p>Isotropic variance factor for the initial covariance <code>S0 * I</code>.</p> </li> <li> <code>nsamples</code>               (<code>int</code>)           \u2013            <p>Number of particles sampled at each snapshot time.</p> </li> <li> <code>ndim</code>               (<code>int</code>)           \u2013            <p>State dimension.</p> </li> <li> <code>Dt</code>               (<code>float</code>)           \u2013            <p>Snapshot interval in simulation time.</p> </li> <li> <code>K</code>               (<code>int</code>)           \u2013            <p>Number of snapshots.</p> </li> <li> <code>dt</code>               (<code>float</code>, default:                   <code>0.006</code> )           \u2013            <p>Euler-Maruyama integration step.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>samples</code> (              <code>list of length K</code> )          \u2013            <p><code>samples[k]</code> is an ndarray of shape <code>(nsamples, ndim)</code>.</p> </li> <li> <code>tt</code> (              <code>ndarray of shape (K,)</code> )          \u2013            <p>Snapshot times.</p> </li> </ul>"},{"location":"api/pfi/utils/#pfi.utils.simulate_toggle_switch","title":"<code>simulate_toggle_switch(nsamples, init, nsnaps, ndim, seed, maxiter, model_params, vol, gr, growth_flag=False)</code>","text":"<p>Simulate stochastic toggle-switch dynamics with optional growth.</p> <p>Parameters:</p> <ul> <li> <code>nsamples</code>               (<code>int</code>)           \u2013            <p>Initial number of particles.</p> </li> <li> <code>init</code>               (<code>ndarray of shape (ndim, nsamples)</code>)           \u2013            <p>Initial state matrix.</p> </li> <li> <code>nsnaps</code>               (<code>int</code>)           \u2013            <p>Number of snapshot times.</p> </li> <li> <code>ndim</code>               (<code>int</code>)           \u2013            <p>State dimension.</p> </li> <li> <code>seed</code>               (<code>int</code>)           \u2013            <p>Random seed.</p> </li> <li> <code>maxiter</code>               (<code>int</code>)           \u2013            <p>Number of discrete integration iterations.</p> </li> <li> <code>model_params</code>               (<code>array-like of shape (7,)</code>)           \u2013            <p>Toggle-switch parameters <code>[a1, a2, b1, b2, k1, k2, n]</code>.</p> </li> <li> <code>vol</code>               (<code>float</code>)           \u2013            <p>System volume scaling the stochastic term.</p> </li> <li> <code>gr</code>               (<code>float</code>)           \u2013            <p>Growth-rate scale used when <code>growth_flag=True</code>.</p> </li> <li> <code>growth_flag</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If <code>True</code>, cells are duplicated according to growth probabilities.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>samples_full</code> (              <code>list of length nsnaps</code> )          \u2013            <p><code>samples_full[k]</code> is an ndarray of shape <code>(n_k, ndim)</code>, where <code>n_k</code> can increase across snapshots when growth is enabled.</p> </li> <li> <code>tt</code> (              <code>ndarray of shape (nsnaps,)</code> )          \u2013            <p>Snapshot times.</p> </li> </ul>"},{"location":"api/pfi/utils/#pfi.utils.snapshots_from_X","title":"<code>snapshots_from_X(X)</code>","text":"<p>Split a time-augmented dataset into per-time snapshots.</p> <p>Parameters:</p> <ul> <li> <code>X</code>               (<code>array-like of shape (n_samples_total, ndim + 1)</code>)           \u2013            <p>Input matrix with time stored in the last column.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>snaps</code> (              <code>list of torch.Tensor, length n_unique_times</code> )          \u2013            <p><code>snaps[k]</code> has shape <code>(n_k, ndim)</code>.</p> </li> <li> <code>times</code> (              <code>torch.Tensor of shape (n_unique_times,)</code> )          \u2013            <p>Sorted unique times found in <code>X</code>.</p> </li> </ul>"},{"location":"api/pfi/utils/#pfi.utils.toggle_switch","title":"<code>toggle_switch(x, model_params)</code>","text":"<p>Evaluate the deterministic toggle-switch production term.</p> <p>Parameters:</p> <ul> <li> <code>x</code>               (<code>ndarray of shape (n_samples, 2)</code>)           \u2013            <p>State values, where each row is <code>[x1, x2]</code>.</p> </li> <li> <code>model_params</code>               (<code>array-like of shape (7,)</code>)           \u2013            <p>Model parameters <code>[a1, a2, b1, b2, k1, k2, n]</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>f</code> (              <code>ndarray of shape (n_samples, 2)</code> )          \u2013            <p>Deterministic production term for each sample.</p> </li> </ul>"},{"location":"api/pfi/utils/data/","title":"data","text":""},{"location":"api/pfi/utils/data/#pfi.utils.data","title":"<code>pfi.utils.data</code>","text":"<p>Data reshaping and snapshot conversion helpers for PFI estimators.</p>"},{"location":"api/pfi/utils/data/#pfi.utils.data.X_from_snapshots","title":"<code>X_from_snapshots(snaps, times)</code>","text":"<p>Stack snapshots into a single array with appended time column.</p> <p>Parameters:</p> <ul> <li> <code>snaps</code>               (<code>list of ndarray, length n_snaps</code>)           \u2013            <p><code>snaps[k]</code> has shape <code>(n_k, ndim)</code>.</p> </li> <li> <code>times</code>               (<code>array-like of shape (n_snaps,)</code>)           \u2013            <p>Snapshot times aligned with <code>snaps</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>X</code> (              <code>ndarray of shape (sum_k n_k, ndim + 1)</code> )          \u2013            <p>Concatenated dataset where last column stores time.</p> </li> </ul>"},{"location":"api/pfi/utils/data/#pfi.utils.data.snapshots_from_X","title":"<code>snapshots_from_X(X)</code>","text":"<p>Split a time-augmented dataset into per-time snapshots.</p> <p>Parameters:</p> <ul> <li> <code>X</code>               (<code>array-like of shape (n_samples_total, ndim + 1)</code>)           \u2013            <p>Input matrix with time stored in the last column.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>snaps</code> (              <code>list of torch.Tensor, length n_unique_times</code> )          \u2013            <p><code>snaps[k]</code> has shape <code>(n_k, ndim)</code>.</p> </li> <li> <code>times</code> (              <code>torch.Tensor of shape (n_unique_times,)</code> )          \u2013            <p>Sorted unique times found in <code>X</code>.</p> </li> </ul>"},{"location":"api/pfi/utils/data/#pfi.utils.data.subsample_shuffle","title":"<code>subsample_shuffle(snaps)</code>","text":"<p>Shuffle each snapshot and subsample to a common sample count.</p> <p>Parameters:</p> <ul> <li> <code>snaps</code>               (<code>list of array-like, length n_snaps</code>)           \u2013            <p><code>snaps[k]</code> has shape <code>(n_k, ndim)</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>dist</code> (              <code>list of ndarray, length n_snaps</code> )          \u2013            <p>Shuffled snapshots with common shape <code>(n_min, ndim)</code> where <code>n_min = min_k n_k</code>.</p> </li> </ul>"},{"location":"api/pfi/utils/nns/","title":"nns","text":""},{"location":"api/pfi/utils/nns/#pfi.utils.nns","title":"<code>pfi.utils.nns</code>","text":"<p>Neural-network building blocks and differential operators for PFI.</p>"},{"location":"api/pfi/utils/nns/#pfi.utils.nns.BatchNorm","title":"<code>BatchNorm(mean, std)</code>","text":"<p>               Bases: <code>object</code></p> <p>Simple affine normalizer <code>(x - mean) / std</code>.</p> <p>Parameters:</p> <ul> <li> <code>mean</code>               (<code>float or torch.Tensor of shape (n_features,) or (1, n_features)</code>)           \u2013            <p>Feature-wise mean.</p> </li> <li> <code>std</code>               (<code>float or torch.Tensor of shape (n_features,) or (1, n_features)</code>)           \u2013            <p>Feature-wise standard deviation.</p> </li> </ul>"},{"location":"api/pfi/utils/nns/#pfi.utils.nns.DNN","title":"<code>DNN(sizes, mean=0, std=1, seed=0, activation=nn.Tanh())</code>","text":"<p>               Bases: <code>Module</code></p> <p>Fully-connected network with optional feature normalization.</p> <p>Parameters:</p> <ul> <li> <code>sizes</code>               (<code>list of int</code>)           \u2013            <p>Layer sizes including input and output dimensions.</p> </li> <li> <code>mean</code>               (<code>float or Tensor</code>, default:                   <code>0</code> )           \u2013            <p>Initial mean used by the internal normalizer.</p> </li> <li> <code>std</code>               (<code>float or Tensor</code>, default:                   <code>1</code> )           \u2013            <p>Initial standard deviation used by the internal normalizer.</p> </li> <li> <code>seed</code>               (<code>int</code>, default:                   <code>0</code> )           \u2013            <p>Random seed for layer initialization.</p> </li> <li> <code>activation</code>               (<code>Module</code>, default:                   <code>torch.nn.Tanh()</code> )           \u2013            <p>Hidden activation module.</p> </li> </ul>"},{"location":"api/pfi/utils/nns/#pfi.utils.nns.DNN.set_scales","title":"<code>set_scales(mean, std)</code>","text":"<p>Update normalization statistics.</p> <p>Parameters:</p> <ul> <li> <code>mean</code>               (<code>torch.Tensor of shape (1, n_features)</code>)           \u2013            <p>New feature means.</p> </li> <li> <code>std</code>               (<code>torch.Tensor of shape (1, n_features)</code>)           \u2013            <p>New feature standard deviations.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>self</code> (              <code>DNN</code> )          \u2013            <p>Estimator instance.</p> </li> </ul>"},{"location":"api/pfi/utils/nns/#pfi.utils.nns.FastTensorDataLoader","title":"<code>FastTensorDataLoader(*tensors, batch_size=32, shuffle=False)</code>","text":"<p>Lightweight mini-batch iterator over in-memory tensors.</p> <p>Parameters:</p> <ul> <li> <code>*tensors</code>               (<code>tuple of torch.Tensor</code>, default:                   <code>()</code> )           \u2013            <p>Tensors with matching first dimension.</p> </li> <li> <code>batch_size</code>               (<code>int</code>, default:                   <code>32</code> )           \u2013            <p>Number of samples per yielded batch.</p> </li> <li> <code>shuffle</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If <code>True</code>, shuffle samples at each iteration.</p> </li> </ul>"},{"location":"api/pfi/utils/nns/#pfi.utils.nns.FreezeVarDNN","title":"<code>FreezeVarDNN(dnn, var_index, var_value)</code>","text":"<p>               Bases: <code>Module</code></p> <p>Wrapper that fixes one input feature to a constant before inference.</p> <p>Parameters:</p> <ul> <li> <code>dnn</code>               (<code>Module</code>)           \u2013            <p>Base network receiving <code>n_features</code> inputs.</p> </li> <li> <code>var_index</code>               (<code>int</code>)           \u2013            <p>Index of the feature to overwrite.</p> </li> <li> <code>var_value</code>               (<code>float</code>)           \u2013            <p>Constant value assigned to that feature.</p> </li> </ul>"},{"location":"api/pfi/utils/nns/#pfi.utils.nns.LayerNoWN","title":"<code>LayerNoWN(in_features, out_features, seed, activation)</code>","text":"<p>               Bases: <code>Module</code></p> <p>Linear layer with Xavier initialization and no weight normalization.</p> <p>Parameters:</p> <ul> <li> <code>in_features</code>               (<code>int</code>)           \u2013            <p>Input feature dimension.</p> </li> <li> <code>out_features</code>               (<code>int</code>)           \u2013            <p>Output feature dimension.</p> </li> <li> <code>seed</code>               (<code>int</code>)           \u2013            <p>Random seed used for initialization.</p> </li> <li> <code>activation</code>               (<code>Module</code>)           \u2013            <p>Activation used in surrounding network to set initialization gain.</p> </li> </ul>"},{"location":"api/pfi/utils/nns/#pfi.utils.nns.SpectralNormDNN","title":"<code>SpectralNormDNN(sizes, mean=0, std=1, seed=0, activation=nn.Tanh())</code>","text":"<p>               Bases: <code>Module</code></p> <p>Fully-connected network with spectral normalization on hidden layers.</p> <p>Parameters:</p> <ul> <li> <code>sizes</code>               (<code>list of int</code>)           \u2013            <p>Layer sizes including input and output dimensions.</p> </li> <li> <code>mean</code>               (<code>float or Tensor</code>, default:                   <code>0</code> )           \u2013            <p>Initial mean used by the internal normalizer.</p> </li> <li> <code>std</code>               (<code>float or Tensor</code>, default:                   <code>1</code> )           \u2013            <p>Initial standard deviation used by the internal normalizer.</p> </li> <li> <code>seed</code>               (<code>int</code>, default:                   <code>0</code> )           \u2013            <p>Random seed for layer initialization.</p> </li> <li> <code>activation</code>               (<code>Module</code>, default:                   <code>torch.nn.Tanh()</code> )           \u2013            <p>Hidden activation module.</p> </li> </ul>"},{"location":"api/pfi/utils/nns/#pfi.utils.nns.SpectralNormDNN.set_scales","title":"<code>set_scales(mean, std)</code>","text":"<p>Update normalization statistics.</p> <p>Parameters:</p> <ul> <li> <code>mean</code>               (<code>torch.Tensor of shape (1, n_features)</code>)           \u2013            <p>New feature means.</p> </li> <li> <code>std</code>               (<code>torch.Tensor of shape (1, n_features)</code>)           \u2013            <p>New feature standard deviations.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>self</code> (              <code>SpectralNormDNN</code> )          \u2013            <p>Estimator instance.</p> </li> </ul>"},{"location":"api/pfi/utils/nns/#pfi.utils.nns.divergence","title":"<code>divergence(field, x)</code>","text":"<p>Compute coordinate-wise divergence terms of a vector field.</p> <p>Parameters:</p> <ul> <li> <code>field</code>               (<code>torch.Tensor of shape (batch_size, ndim)</code>)           \u2013            <p>Vector field evaluated at <code>x</code>.</p> </li> <li> <code>x</code>               (<code>torch.Tensor of shape (batch_size, ndim)</code>)           \u2013            <p>Input points with gradient tracking enabled.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>div</code> (              <code>torch.Tensor of shape (batch_size, ndim)</code> )          \u2013            <p>Diagonal Jacobian terms, one per coordinate.</p> </li> </ul>"},{"location":"api/pfi/utils/nns/#pfi.utils.nns.loss_grad_std","title":"<code>loss_grad_std(loss, net, device)</code>","text":"<p>Estimate the pooled standard deviation of layer gradients.</p> <p>Parameters:</p> <ul> <li> <code>loss</code>               (<code>torch.Tensor of shape ()</code>)           \u2013            <p>Scalar loss value.</p> </li> <li> <code>net</code>               (<code>Module</code>)           \u2013            <p>Network containing linear layers.</p> </li> <li> <code>device</code>               (<code>str or device</code>)           \u2013            <p>Device used for intermediate tensors.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>std</code> (              <code>torch.Tensor of shape ()</code> )          \u2013            <p>Pooled gradient standard deviation across linear layer parameters.</p> </li> </ul>"},{"location":"api/pfi/utils/simulations/","title":"simulations","text":""},{"location":"api/pfi/utils/simulations/#pfi.utils.simulations","title":"<code>pfi.utils.simulations</code>","text":"<p>Simulation utilities for benchmark dynamical systems.</p>"},{"location":"api/pfi/utils/simulations/#pfi.utils.simulations.g_rate","title":"<code>g_rate(x1, x2, gr)</code>","text":"<p>Compute the cell growth rate used in the toggle-switch simulator.</p> <p>Parameters:</p> <ul> <li> <code>x1</code>               (<code>ndarray of shape (n_samples,)</code>)           \u2013            <p>First coordinate of the state.</p> </li> <li> <code>x2</code>               (<code>ndarray of shape (n_samples,)</code>)           \u2013            <p>Second coordinate of the state.</p> </li> <li> <code>gr</code>               (<code>float</code>)           \u2013            <p>Growth-rate scale.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>rate</code> (              <code>ndarray of shape (n_samples,)</code> )          \u2013            <p>Growth rate for each sample.</p> </li> </ul>"},{"location":"api/pfi/utils/simulations/#pfi.utils.simulations.simulate_ornstein_uhlenbeck","title":"<code>simulate_ornstein_uhlenbeck(Om, D, m0, S0, nsamples, ndim, Dt, K, dt=0.006)</code>","text":"<p>Simulate snapshots from a linear Ornstein-Uhlenbeck process.</p> <p>Parameters:</p> <ul> <li> <code>Om</code>               (<code>ndarray of shape (ndim, ndim)</code>)           \u2013            <p>Drift matrix.</p> </li> <li> <code>D</code>               (<code>ndarray of shape (ndim, ndim)</code>)           \u2013            <p>Diffusion matrix.</p> </li> <li> <code>m0</code>               (<code>ndarray of shape (ndim,)</code>)           \u2013            <p>Mean of the initial Gaussian distribution.</p> </li> <li> <code>S0</code>               (<code>float</code>)           \u2013            <p>Isotropic variance factor for the initial covariance <code>S0 * I</code>.</p> </li> <li> <code>nsamples</code>               (<code>int</code>)           \u2013            <p>Number of particles sampled at each snapshot time.</p> </li> <li> <code>ndim</code>               (<code>int</code>)           \u2013            <p>State dimension.</p> </li> <li> <code>Dt</code>               (<code>float</code>)           \u2013            <p>Snapshot interval in simulation time.</p> </li> <li> <code>K</code>               (<code>int</code>)           \u2013            <p>Number of snapshots.</p> </li> <li> <code>dt</code>               (<code>float</code>, default:                   <code>0.006</code> )           \u2013            <p>Euler-Maruyama integration step.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>samples</code> (              <code>list of length K</code> )          \u2013            <p><code>samples[k]</code> is an ndarray of shape <code>(nsamples, ndim)</code>.</p> </li> <li> <code>tt</code> (              <code>ndarray of shape (K,)</code> )          \u2013            <p>Snapshot times.</p> </li> </ul>"},{"location":"api/pfi/utils/simulations/#pfi.utils.simulations.simulate_toggle_switch","title":"<code>simulate_toggle_switch(nsamples, init, nsnaps, ndim, seed, maxiter, model_params, vol, gr, growth_flag=False)</code>","text":"<p>Simulate stochastic toggle-switch dynamics with optional growth.</p> <p>Parameters:</p> <ul> <li> <code>nsamples</code>               (<code>int</code>)           \u2013            <p>Initial number of particles.</p> </li> <li> <code>init</code>               (<code>ndarray of shape (ndim, nsamples)</code>)           \u2013            <p>Initial state matrix.</p> </li> <li> <code>nsnaps</code>               (<code>int</code>)           \u2013            <p>Number of snapshot times.</p> </li> <li> <code>ndim</code>               (<code>int</code>)           \u2013            <p>State dimension.</p> </li> <li> <code>seed</code>               (<code>int</code>)           \u2013            <p>Random seed.</p> </li> <li> <code>maxiter</code>               (<code>int</code>)           \u2013            <p>Number of discrete integration iterations.</p> </li> <li> <code>model_params</code>               (<code>array-like of shape (7,)</code>)           \u2013            <p>Toggle-switch parameters <code>[a1, a2, b1, b2, k1, k2, n]</code>.</p> </li> <li> <code>vol</code>               (<code>float</code>)           \u2013            <p>System volume scaling the stochastic term.</p> </li> <li> <code>gr</code>               (<code>float</code>)           \u2013            <p>Growth-rate scale used when <code>growth_flag=True</code>.</p> </li> <li> <code>growth_flag</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If <code>True</code>, cells are duplicated according to growth probabilities.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>samples_full</code> (              <code>list of length nsnaps</code> )          \u2013            <p><code>samples_full[k]</code> is an ndarray of shape <code>(n_k, ndim)</code>, where <code>n_k</code> can increase across snapshots when growth is enabled.</p> </li> <li> <code>tt</code> (              <code>ndarray of shape (nsnaps,)</code> )          \u2013            <p>Snapshot times.</p> </li> </ul>"},{"location":"api/pfi/utils/simulations/#pfi.utils.simulations.toggle_switch","title":"<code>toggle_switch(x, model_params)</code>","text":"<p>Evaluate the deterministic toggle-switch production term.</p> <p>Parameters:</p> <ul> <li> <code>x</code>               (<code>ndarray of shape (n_samples, 2)</code>)           \u2013            <p>State values, where each row is <code>[x1, x2]</code>.</p> </li> <li> <code>model_params</code>               (<code>array-like of shape (7,)</code>)           \u2013            <p>Model parameters <code>[a1, a2, b1, b2, k1, k2, n]</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>f</code> (              <code>ndarray of shape (n_samples, 2)</code> )          \u2013            <p>Deterministic production term for each sample.</p> </li> </ul>"}]}